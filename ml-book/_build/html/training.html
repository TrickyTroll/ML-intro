
<!DOCTYPE html>

<html lang="fr">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>L’entrainement d’un système neuronal &#8212; Introduction à la reconnaissance optique de caractère</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/translations.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Recherche" href="search.html" />
    <link rel="next" title="Bienfaits et inconvénients" href="bienfaits_et_inconv%C3%A9nients.html" />
    <link rel="prev" title="Notions de base" href="notions_de_base.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Introduction à la reconnaissance optique de caractère</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Rechercher dans ce livre ..." aria-label="Rechercher dans ce livre ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Préface
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="rapport_final.html">
   Rapport Final
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="intro_finale.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="explications_librairies.html">
     Les librairies nécessaires
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="preprocessing.html">
     Traitement antérieur à l’entrainement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="notions_de_base.html">
     Notions de base
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     L’entrainement d’un système neuronal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="bienfaits_et_inconv%C3%A9nients.html">
     Bienfaits et inconvénients
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="conclusion.html">
     Conclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="zbib.html">
     Bibliographie
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Basculer la navigation" aria-controls="site-navigation"
            title="Basculer la navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Téléchargez cette page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/training.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Télécharger le fichier source" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Imprimer au format PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Mode plein écran"
                title="Mode plein écran"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contenu
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fonction-d-erreur">
   Fonction d’erreur
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transmition-de-l-information">
   Transmition de l’information
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#back-propagation">
   <em>
    Back propagation
   </em>
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="l-entrainement-d-un-systeme-neuronal">
<h1>L’entrainement d’un système neuronal<a class="headerlink" href="#l-entrainement-d-un-systeme-neuronal" title="Lien permanent vers ce titre">¶</a></h1>
<p>L’entrainement d’un réseau à l’aide d’une certaine base de données (donnée d’entrainement) permet à celui-ci de prédire le résultat
d’une autre base donnée. En effet, le but d’un réseau neuronal est de réduire l’erreur de l’entrainement ainsi que la différence
entre l’erreur des données entrainées et l’erreur des données de test soient petites. Lorsque le réseau est sous-entrainé,
le réseau de sera pas précis lors de ces résultats. Cependant, lorsque le réseau est sur-entrainé, celui-ci va prendre en compte
tout le bruit des données. Ce bruit peut être, par exemple, le fait de prendre en compte les imperfections d’une image, reconnaitre
seulement certains styles d’écriture, etc. Cela a comme impact d’augmenter l’erreur lorsque le système est exposé à une nouvelle base de données.</p>
<div class="figure align-default" id="overfitting">
<img alt="_images/overfitting.png" src="_images/overfitting.png" />
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Graphiques représentant l’effet de l’entrainement du réseau de neurone</span><a class="headerlink" href="#overfitting" title="Lien permanent vers cette image">¶</a></p>
</div>
<p>L’entrainement d’un réseau neuronal s’effectue à l’inverse. Visuellement, l’entrainement et l’ajustement des différents
paramètres se font de la droite vers la gauche. Ce principe, appelé « backpropagation », va être expliqué à l’aide quelques
démonstrations mathématiques complémentées par quelques explications écrites.</p>
<div class="section" id="fonction-d-erreur">
<h2>Fonction d’erreur<a class="headerlink" href="#fonction-d-erreur" title="Lien permanent vers ce titre">¶</a></h2>
<p>Une fonction d’erreur est une fonction permettant de connaitre la précision des résultats des extrants de la dernière
couche. Il peut y avoir plusieurs fonctions d’erreur. En voici un exemple:</p>
<p><span class="math notranslate nohighlight">\(E_{SS}=1/2\sum_{i=1}^nE_i^2 \)</span> <strong>(1.1)</strong></p>
<p><span class="math notranslate nohighlight">\(E_{SS}=1/2\sum_{i=1}^nE_i^2 \)</span> <strong>(1.2)</strong></p>
<p>où <span class="math notranslate nohighlight">\(E_{SS}\)</span>= « error sum of square ». Cela est tout simplement une de plusieurs fonctions d’erreur.</p>
<p><span class="math notranslate nohighlight">\(E_i =|{t_i-I_i}|\)</span> <strong>(1.3)</strong></p>
<p>où <span class="math notranslate nohighlight">\(E_i\)</span> correspond à l’erreur d’un neurone de la dernière couche (extrant). <span class="math notranslate nohighlight">\(I_i\)</span> correspond à la valeur numérique
d’un extrant et <span class="math notranslate nohighlight">\(t_i\)</span> correspond à la valeur désirée provenant de la base de données fournies.</p>
<p>Combiner les deux équations permet d’obtenir:</p>
<p><span class="math notranslate nohighlight">\(E=1/2\sum_{i=1}^n({T_i-Y_i})^2\)</span> <strong>(1.4)</strong></p>
</div>
<div class="section" id="transmition-de-l-information">
<h2>Transmition de l’information<a class="headerlink" href="#transmition-de-l-information" title="Lien permanent vers ce titre">¶</a></h2>
<blockquote>
<div><p>Note: Afin de simplifier les explications, ces dernières seront faites en utilisant un réseau neuronal ayant seulement 1 neurone par couche.</p>
</div></blockquote>
<p>D’abord, il faut comprendre comment le réseau transmet son information de cellules en cellule. En effet,
un neurone ayant contenant une certaine valeur <span class="math notranslate nohighlight">\(Y\)</span> transmet cette dernière à tous les autres neurones de
la prochaine couche. Cependant, ces transmitions n’ont pas toutes les mêmes poids. Ces poids <span class="math notranslate nohighlight">\(p\)</span> diffèrent
afin de favoriser certaines activations et en défavoriser d’autres. Chaque liaison entre chaque neurone possède
un poid propre à chacune. Ces derniers sont multipliés avec l’extrant de la neurone en précédentes.</p>
<p><span class="math notranslate nohighlight">\(Y_{i} = Y_{i-1}\times p_{i}\)</span><strong>(2.0)</strong></p>
<p>où <span class="math notranslate nohighlight">\(p_{i}\)</span> correspond au poid de la neurone de la couche i</p>
<p>Ensuite, un biais <span class="math notranslate nohighlight">\(b\)</span> est additionné ou soustrait au résultat précédent</p>
<p><span class="math notranslate nohighlight">\(Y_i = Y_{i-1}\times p_{i} + b_i\)</span> <strong>(2.1)</strong></p>
<p>d’activation sera expliqué en détail plus loin.où <span class="math notranslate nohighlight">\(b_i\)</span> correspond au biais de la neurone de la couche i.</p>
<p>Finalement, une fonction d’activation <span class="math notranslate nohighlight">\(a\)</span> est ajoutée au reste de la formule. L’utilité et le fonctionnement de
la fonction d’activation sera expliqué en détail plus loin.</p>
<p><span class="math notranslate nohighlight">\(Y_i = a\times(Y_{i-1}\times p_{i} + b_i)\)</span>
<strong>(2.2)</strong></p>
</div>
<div class="section" id="back-propagation">
<h2><em>Back propagation</em><a class="headerlink" href="#back-propagation" title="Lien permanent vers ce titre">¶</a></h2>
<p>L’objectif est de comprendre comment le poids et le biais doit être ajuster en débutant de la fonction d’erreur et d’activation.</p>
<p>Dabord, en utilisant la formule de base de transmission d’un neurone (sans le biais) :</p>
<p><span class="math notranslate nohighlight">\(Y = \sum_{i=1}^{n} I_i \times p_i \)</span></p>
<p>Il est possible de comprendre comment le changement d’une variable impact une autre. Les dérivés seront
donc utilisées afin de démontrer ce principe.</p>
<p><span class="math notranslate nohighlight">\(\frac{dY}{dI_i}=\frac{dY}{dI_i}\sum_{i=1}^{n} I_i \times p_{ji} 
\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{dY}{dI_i} = p_i\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{dY}{dp_i} = I_i\)</span></p>
<p>Cela veut donc dire que le poid influence le résultat de l’extrant et que l’intrant influence
le résultat de l’extrant.</p>
<p>En utlisant la formule (1.4) et le concept de dérivée partielle, il est possible de comprendre
l’impact d’un changement de la valeur de l’intrant <span class="math notranslate nohighlight">\(I_i\)</span> sur l’erreur:</p>
<p><span class="math notranslate nohighlight">\(\frac{dE}{dI_i} =  (2/2)(t_i - I_i)(-1) \)</span>
<span class="math notranslate nohighlight">\(\frac{dE}{dI_i}= -(t_i-I_i)\)</span></p>
<p>Maintenant, il faut calculer la dérivation de la fonction d’activation.
La fonction sigmoïde sera utilisée pour cet exemple.</p>
<p><span class="math notranslate nohighlight">\(a = \frac{1}{1 + e^{-Y}} =(1+e^{-Y})^{-1}\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{da}{dY} = -1 (-e^{-Y})(1+e^{-Y})^{-2} \)</span></p>
<p><span class="math notranslate nohighlight">\(= \frac{e^{-Y}}{(1+e^{-Y})^2} \)</span></p>
<p><span class="math notranslate nohighlight">\(= \frac{1}{(1+e^{-Y})}\times\frac{e^{-Y}}{(1+e^{-Y})} \)</span></p>
<p><span class="math notranslate nohighlight">\(= a \times \frac{e^{-Y}}{(1+e^{-Y})}\)</span></p>
<p><span class="math notranslate nohighlight">\(= a \times \frac{1+e^{-Y}-1}{(1+e^{-Y})} \)</span></p>
<p><span class="math notranslate nohighlight">\(= a \times (\frac{(1+e^{-Y})}{(1+e^{-Y})} + \frac{-1}{(1+e^{-Y})})\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{da}{dY}= a \times (1-a)\)</span></p>
<p>Maintenant il est possible, à l’aide de la règle de dérivation en chaine, de trouver l’impact
qu’a <span class="math notranslate nohighlight">\(Y\)</span> sur l’erreur <span class="math notranslate nohighlight">\(E\)</span>. Dans cet exemple, <span class="math notranslate nohighlight">\(I_i = a \)</span> puisque la fonction d’activation été appliquée au neurone en question.</p>
<p><span class="math notranslate nohighlight">\(\frac{dE}{dY_i} = \frac{dE}{dI_i} \times \frac{dI_i}{dY_i}\)</span></p>
<p><span class="math notranslate nohighlight">\(= \frac{dE}{dI_i} \times \frac{da}{dY_i}\)</span></p>
<p><span class="math notranslate nohighlight">\(=-(t_i - I_i)  I_i (1- I_i)\)</span>  <strong>(3.0)</strong></p>
<p>Ensuite il est possible de calculer la dérivation de l’erreur en fonction du poid <span class="math notranslate nohighlight">\(p_{ji}\)</span> d’une liaison entre deux neurones.</p>
<p><span class="math notranslate nohighlight">\(\frac{dE}{dp_{ji}} =\frac{dE}{dY_i} \times \frac{dY_i}{dp_{ji}} \)</span></p>
<p><span class="math notranslate nohighlight">\(= (-(t_i - I_i) \times I_i\times (1- I_i))\times I_i\)</span></p>
<p><span class="math notranslate nohighlight">\(= -I_i I_j (1-I_i)(t_i-I_i)\)</span><strong>(4.0)</strong></p>
<p>Cette équation signifie que le changement de l’erreur influence le poid et cette influence
correspond à l’extrant d’un neurone négatif multiplié par l’extrant du neurone précédent et
ce tout est multplié par 1 moins la valeur du neurone. À ce résultat est multiplié la valeur
de l’erreur soit : <span class="math notranslate nohighlight">\((t_i-I_i)\)</span>
L’équation 3.0 sera représenté par la variable:  <span class="math notranslate nohighlight">\(\Delta p\)</span></p>
<p>Le concept de « backpropagation » se résume donc a:</p>
<p><span class="math notranslate nohighlight">\(p_{ji} = p_{ji} + \Delta p\)</span></p>
<p>Le poids d’un neurone change légèrement en additionnant un <span class="math notranslate nohighlight">\(\Delta p\)</span>  positif ou négatif. Ce changement
est fait avec une plus grande importance plus le neurone est proche de la couche des extrants. Cela est
dû au fait que l’apprentissage commence par la couche finale pour enfin se rendre jusqu’à la couche débutant
le système neuronal. Les premiers ajustements, donc ceux des couches plus proches de la fin, sont plus importants.
Les couches se situant plus au début du réseau vont plutôt avoir de petits changements à leur poids puisque
rendu à l’ajustement de dce dernier, l’erreur est déja considérablement réduite. Ce concept se nomme descente
de gradient stochastique.</p>
<p>###Origine du biais
Certains problèmes peuvent survenir avec le concept de descente de gradiant dans un réseau neuronal.
En effet, lorsqu’une couche « n’apprend plus » ou, en d’autres mots, lorsque le poids ne varie plus,
on assiste a un problème se nommant la disparition du gradiant. Cela est un problème pour le réseau puisque
le tout l’entrainement se fait uniquement dans les dernières couches. Un autre problème est que le gradiant
dans une fonction de coût telle une sigoïde, le gradient se situe uniquement au milieu de la fonction comme
le montre le graphique ci-dessous.</p>
<div class="figure align-default" id="tanh">
<img alt="_images/tanh.png" src="_images/tanh.png" />
<p class="caption"><span class="caption-number">Fig. 6 </span><span class="caption-text">Fonction sigmoïde</span><a class="headerlink" href="#tanh" title="Lien permanent vers cette image">¶</a></p>
</div>
<p>En effet, les extrémités de la fonction forment un plateau. Il n’y a donc pas de changement
possible puisque soit l’intrant est multiplié par 1, ce qui ne change pas le résultat, ou bien
soit le résultat est multiplié par 0 ce qui rend la valeurr nul et cela est néfaste pour un réseau neuronal.
En effet, une valeur égale a 0 empêche l’entrainement du réseau puisque peut importe la variation
du poid, <span class="math notranslate nohighlight">\(0\times p\)</span> sera toujours être égale à 0. C’est pour remédier à cette erreur qu’un biais est ajouté
à la fonction.</p>
<p><span class="math notranslate nohighlight">\(Y =\sum_{i=1}^{n} I_i \times p_i + b\)</span></p>
<p>L’ajout de ce biais va permettre de conserver un apprentissage même lorsque la valeur d’un neurone est figée à 0.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="notions_de_base.html" title="previous page">Notions de base</a>
    <a class='right-next' id="next-link" href="bienfaits_et_inconv%C3%A9nients.html" title="next page">Bienfaits et inconvénients</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Émile Bergeron, Samuel Paquin, Étienne Parent, Jérémie Sanfaçon<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>