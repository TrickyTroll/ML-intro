%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,french]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Sonny]{fncychap}
\ChNameVar{\Large\normalfont\sffamily}
\ChTitleVar{\Large\normalfont\sffamily}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}




\title{Introduction à la reconnaissance optique de caractère}
\date{nov. 26, 2020}
\release{}
\author{Émile Bergeron, Samuel Paquin, Étienne Parent, Jérémie Sanfaçon}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{intro::doc}}


La documentation sur l’utilisation de ce site n’a pas encore été faite. :)


\chapter{Rapport de mi\sphinxhyphen{}session}
\label{\detokenize{rapport_final:rapport-de-mi-session}}\label{\detokenize{rapport_final::doc}}
Cette section contient notre rapport final.


\section{Introduction}
\label{\detokenize{intro_finale:introduction}}\label{\detokenize{intro_finale::doc}}

\subsection{Mise en contexte}
\label{\detokenize{intro_finale:mise-en-contexte}}
L’intelligence artificielle est au coeur de l’actualité depuis près d’une
décennie. Elle est déjà entrain de changer le monde , et ce, dans plusieurs
secteurs incluant la finance, la sécurité, la santé, la justice criminelle,
les moyens de transport, la publicité, et plusieurs autres.

Que ça soit des décisions sur l’investissement d’un portefeuille
d’un individu ou de la détection de fraude en identifiant des anormalités, l’intelligence
artificielle est de plus en plus présente dans le secteur de la finance. \sphinxcite{zbiblio_commented:nytimes}

Du côté de la
sécurité, un excellent exemple serait \sphinxhref{https://en.wikipedia.org/wiki/Project\_Maven}{Project Maven}
un projet d” intelligence artificielle du \sphinxhref{https://en.wikipedia.org/wiki/The\_Pentagon}{Pentagon}
des États\sphinxhyphen{}Unis qui est capable de passer à travers plusieurs informations,
vidéos et photos pour détecter des dangers potentiels.

L’intelligence artificielle est très importante dans la santé avec des compagnies comme
\sphinxhref{https://www.merantix.com/}{Merantix}, une compagnie allemande qui a permis de détecter
des ganglions lymphatiques ainsi que des problèmes liés à ceux\sphinxhyphen{}ci tels que des lésions
ou des cancers. L’étude de séquence d’ADN par l’intelligence artificielle permet de détecter
des maladies génétiques et des cancers.

Un des domaines le plus importants en ce moment serait, les moyens de transport avec plus de \$80
milliards investis dans des véhicules de conduite autonome entre 2014 et 2017. L’intelligence
artificielle dans ce domaine aurait pour but de diminuer grandement l’erreur humaine dans les transports
et réduire à presque zéro les accidents si la majorité des autos était intelligente. De plus, cela réduirait
aussi grandement le trafic grâce à la communication entre les automobiles intelligentes. La compagnie \sphinxhref{https://www.tesla.com/}{Tesla}
en est déjà très avancée pour ce qui est de leur auto intelligente. \sphinxcite{zbiblio_commented:gouvqc}

Comme on peut le voir, cette technologie a permis de multiples avancées dans des domaines où
il se fait extrêmement difficile de modéliser la problématique selon une
fonction mathématique particulière. L’analyse de langage en est un bon exemple.
Le travail ne peut être modélisé par une seule fonction mathématique puisque
les conditions souvent changeantes nécessiteraient une multitude de fonctions
différentes pour chaque environnement qui n’est pas réaliste. La solution est
plutôt « d’entraîner » un ordinateur à comprendre le monde qui l’entoure.
Pour continuer avec l’exemple de l’analyse du langage, une solution serait
de fournir à l’ordinateur une immense quantité d’exemples et de solutions afin
qu’il développe la capacité de prédire la solution à de nouveaux exemples.
\sphinxhref{https://github.com/openai/gpt-3}{GPT\sphinxhyphen{}3},
un nouveau modèle d’intelligence artificielle produit par
\sphinxhref{https://openai.com}{OpenAI}, a permis à des développeurs de créer un programme
lui\sphinxhyphen{}même capable de programmer à partir de demandes spécifiques faites par un
utilisateur.


\subsection{Le début de la découverte des inconvénients}
\label{\detokenize{intro_finale:le-debut-de-la-decouverte-des-inconvenients}}
Malgré les avancées incroyables que l’intelligence artificielle a déjà permis et
continuera de permettre dans le futur, elle n’est pas sans ses inconvénients.


\subsubsection{Le biais}
\label{\detokenize{intro_finale:le-biais}}
Au
courant des dernières années, les systèmes intelligents sont de plus en plus
reconnus coupables de discrimination envers certains groupes d’individus. Une
étude réalisée par le \sphinxhref{https://www.nist.gov/}{NIST} à étudié le taux d’erreur de
différents programmes de reconnaissance faciale en fonction des différences de
sexe et d’ethnicité des individus sur les photos analysées. L’étude
présente des taux d’erreur
jusqu’à cent fois plus élevés pour des personnes d’origine asiatique ou
africaine lorsque comparé à des personnes d’origine européenne \sphinxcite{zbiblio_commented:nistbias}.
Le taux d’erreur est aussi plus élevé chez les femmes que chez les hommes, et
ce, peut importe l’origine.

Un autre résultat important de cette étude est que le taux d’erreur associé à la
reconnaissance de personnes asiatiques n’est pas présent dans des programmes
réalisés dans des pays d’Asie. Cette observation permet de déduire l’un des plus
grands problèmes liés à l’intelligence artificielle: le biais.

Contrairement à une fonction mathématique qui transforme un chiffre de manière
définie, les procédés menant à la reconnaissance faciale sont beaucoup plus
flous et souvent très mal compris. Plusieurs considèrent les programmes
entraînés comme des « boîtes noires ». Il est difficile de prédire ce qui sortira
de la boîte lorsque l’on y insère quelque chose, et il est encore plus difficile
de comprendre pourquoi le programme prend certaines décisions plus que d’autres.

Cette imprévisibilité inquiète plusieurs. Elle rend la tâche de corriger le
biais assez ardue. Elle fait aussi en sorte qu’il est difficile de prédire le
comportement du programme dans des cas extrêmes sans avoir à lui faire passer
des tests dans ces conditions. Le biais est donc un phénomène difficile à
corriger, ce qui entraîne des questionnements en rapport aux bienfaits de
l’utilisation de l’intelligence artificielle.

Certaines régions du monde
commencent à bannir l’utilisation de la reconnaissance faciale par les forces
de l’ordre. C’est le cas de la ville de Portland, en Oregon \sphinxcite{zbiblio_commented:cnnportland}.
La ville a décidé de bannir l’utilisation de la technologie suite à des craintes
en liées à son manque de précision, surtout lorsqu’utilisée sur des individus
appartenant à une minorité visible.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{black_box}.png}
\caption{L’analogie de la boîte noire.}\label{\detokenize{intro_finale:boite-noire}}\end{figure}


\subsubsection{Une deuxième révolution industrielle}
\label{\detokenize{intro_finale:une-deuxieme-revolution-industrielle}}
Une autre inquiétude liée à l’intelligence artificielle est l’importante
quantité d’emplois qui risque de disparaître puisqu’ils seront maintenant
occupés par des ordinateurs. Ces inquiétudes sont justifiées. Plusieurs articles,
dont
\sphinxhref{https://www.cnbc.com/2019/01/14/the-oracle-of-ai-these-kinds-of-jobs-will-not-be-replaced-by-robots-.html}{celui\sphinxhyphen{}ci}
publié par CNN ainsi que
\sphinxhref{https://medium.com/@ChanPriya/15-jobs-that-will-never-be-replaced-by-ai-512bfbbed0d6}{cette publication}
sur Medium tentent de rassurer la population en mentionnant des emplois qui ne
pourraient apparemment jamais être remplacés par des ordinateurs. Ils mentionnent
entre autres les emplois créatifs, accompagnés des emplois nécessitant beaucoup
d’interactions humaines.

Pourtant, le domaine de l’IA avance chaque année, et il existe maintenant une
panoplie de programmes capable de
\sphinxhref{https://openai.com/blog/musenet/}{composer de la musique},
\sphinxhref{https://www.nvidia.com/en-us/research/ai-playground/}{maîtriser les arts visuels}
ainsi qu”\sphinxhref{https://www.youtube.com/watch?v=D5VN56jQMWM}{entretenir des conversations au téléphone}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{duplex}.jpeg}
\caption{Le PDG de Google présentant une démonstration de Google Duplex.}\label{\detokenize{intro_finale:duplex-presentation}}\end{figure}

Il est dangereux d’extrapoler le progrès qui a été fait au courant des dernières
années sur les décennies à venir. Certaines lois limitant le développement de
l’IA, ou des limitations physiques au présent rythme d’augmentation de la
puissance de calcul des ordinateurs pourraient survenir grandement ralentir
le développement de la technologie. Si nous tentons tout de même de le faire,
les inquiétudes vécues par plusieurs semblent raisonnables.


\subsection{Comprendre la technologie pour démystifier les inquiétudes}
\label{\detokenize{intro_finale:comprendre-la-technologie-pour-demystifier-les-inquietudes}}
Bien que les précédentes inquiétudes face à l’intelligence artificielle soient
totalement justifiées, elles ne sont pas sans solution. Si son développement
est fait de manière éthique et s’il est bien encadré, nous pourrions en retirer
plus d’avantages que d’inconvénient. Pour bien comprendre les inquiétudes, il
faut d’abord comprendre les enjeux. C’est pourquoi nous tenterons de répondre
à la question suivante.

\sphinxstyleemphasis{Quel est le fonctionnent de l’intelligence artificielle et comment devrait\sphinxhyphen{}elle
être utilisée afin de bénéficier l’être humain?}


\section{Les librairies nécessaires}
\label{\detokenize{explications_librairies:les-librairies-necessaires}}\label{\detokenize{explications_librairies::doc}}
Afin de réaliser ce projet dans des temps raisonnables, nous utilisons des
outils et des données réalisés par des organisations réputées comme Google,
\sphinxhref{https://numpy.org/}{Numpy} et la \sphinxhref{https://matplotlib.org/}{Matplotlib} development team.


\subsection{Tensorflow}
\label{\detokenize{explications_librairies:tensorflow}}
\DUrole{xref,myst}{Tensorflow} est une plateforme nous permettant d’accélérer
le développement de notre application d’apprentissage machine. La librairie
procure un \sphinxhref{https://en.wikipedia.org/wiki/API}{API} en Python donnant accès
à de multiples fonctions utilisées pour obtenir des données et les utiliser
pour entraîner notre programme.


\subsubsection{Historique}
\label{\detokenize{explications_librairies:historique}}
Développée par Google et rendue publique en 2015 \sphinxcite{zbiblio_commented:wikitf}, la librairie
a depuis permis aux masses de développer toutes sortes d’applications
bénéficiant de l’intelligence artificielle. TensorFlow est une version polie
du système DistBelief. DistBelief est un produit du projet The Google Brain.
Après avoir été utilisé pendant quelques années pour des produits Google ainsi
que pour de la recherche, DistBelief est amélioré et rendu publique sous le
nom TensorFlow \sphinxcite{zbiblio_commented:tfpaper}. Aujourd’hui, la
\sphinxhref{https://github.com/tensorflow/tensorflow}{page Github} de TensorFlow mentionne
plus de 100 000 utilisateurs et 2 780 contributeurs. La librairie est utilisée
par de multiples entreprises dont Google, Coca\sphinxhyphen{}Cola, airbnb, Twitter et Intel
\sphinxcite{zbiblio_commented:tfmain}.


\subsubsection{Notre utilisation}
\label{\detokenize{explications_librairies:notre-utilisation}}
Nous utilisons TensorFlow afin de faciliter l’accès à nos données et afin
de créer notre modèle.


\paragraph{Accès aux données}
\label{\detokenize{explications_librairies:acces-aux-donnees}}
Pour entrainer notre modèle, nous utilisons la base de données
\sphinxhref{http://yann.lecun.com/exdb/mnist/}{MNIST}. Bien qu’elle soit très complète,
le format de cette base de donnée est assez complexe
(\DUrole{xref,myst}{Voir la section sur le /preprocessing/}. Heureusement,
la libraire TensorFlow procure un
\sphinxhref{https://www.tensorflow.org/api\_docs/python/tf/keras/datasets/mnist/load\_data}{interface simple}
avec le langage de programmation que nous utilisons.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{(}\PYG{p}{(}\PYG{n}{train\PYGZus{}data}\PYG{p}{,} \PYG{n}{train\PYGZus{}labels}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{n}{test\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}labels}\PYG{p}{)}\PYG{p}{)} \PYG{o}{=} \PYG{n}{mnist}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{num\PYGZus{}data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{vstack}\PYG{p}{(}\PYG{p}{[}\PYG{n}{train\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}data}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{num\PYGZus{}labels} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{hstack}\PYG{p}{(}\PYG{p}{[}\PYG{n}{train\PYGZus{}labels}\PYG{p}{,} \PYG{n}{test\PYGZus{}labels}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

La classe \sphinxcode{\sphinxupquote{mnist}} fournie par la librairie \sphinxcode{\sphinxupquote{Tensorflow}}nous permet de charger en mémoire toutes les données nécessaires en seulement trois lignes.


\paragraph{Entraînement du modèle}
\label{\detokenize{explications_librairies:entrainement-du-modele}}
Le domaine de l’IA s’avère assez complexe. Programmer et entraîner un modèle nécessite des connaissances en mathématiques avancées \sphinxcite{zbiblio_commented:goodfellow-et-al-2016}.

\sphinxcode{\sphinxupquote{Tensorflow}}vise à accélérer le développement de l’intelligence artificielle ainsi que de rendre ce développement accessible aux masses. Afin de simplifier la réalisation de notre programme et afin de le rendre plus efficace, nous comptons donc utiliser les méthodes d’entraînement fournies par la librairie. Pour aider le lecteur à comprendre le fonctionnement du programme (et donc pour éviter le phénomène de la {[}boîte noire{]}(lien vers la section de la boîte noire), chaque fonction utilisée sera décortiquée et expliquée en détails.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{keras}\PYG{o}{.}\PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{[}
    \PYG{n}{keras}\PYG{o}{.}\PYG{n}{layers}\PYG{o}{.}\PYG{n}{Flatten}\PYG{p}{(}\PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{28}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{keras}\PYG{o}{.}\PYG{n}{layers}\PYG{o}{.}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{128}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{relu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{keras}\PYG{o}{.}\PYG{n}{layers}\PYG{o}{.}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}
\PYG{p}{]}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{adam}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
	\PYG{n}{loss}\PYG{o}{=}\PYG{n}{tf}\PYG{o}{.}\PYG{n}{keras}\PYG{o}{.}\PYG{n}{losses}\PYG{o}{.}\PYG{n}{SparseCategoricalCrossentropy}\PYG{p}{(}\PYG{n}{from\PYGZus{}logits}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{,}
              \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{accuracy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{train\PYGZus{}images}\PYG{p}{,} \PYG{n}{train\PYGZus{}labels}\PYG{p}{,} \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}
\end{sphinxVerbatim}

Seulement quelques lignes sont nécessaires à l’entraînement de notre modèle.


\subsection{Numpy}
\label{\detokenize{explications_librairies:numpy}}
\sphinxhref{https://numpy.org}{NumPy} est une librairie facilitant le calcul avec le langage de programmation que nous utilisons pour créer notre modèle.


\subsubsection{Historique}
\label{\detokenize{explications_librairies:id5}}
La libraire à été créée en 2005 et était à l’époque basée sur les librairies \sphinxhref{https://docs.python.org/3/library/numeric.html}{numériques et les modules mathématiques} de Python \sphinxcite{zbiblio_commented:numpy}.
Numpy vise à rendre la réalisation de grands calculs numériques plus simples et optimisée. Plusieurs de ses capacités ont des fonctions homologue dans les logiciels \sphinxhref{https://www.mathworks.com}{Matlab} et \sphinxhref{https://maplesoft.com}{Maple}.


\subsubsection{Notre utilisation}
\label{\detokenize{explications_librairies:id7}}
Comme sera possible de l’observer tout au long de ce rapport, les mathématiques constituent le pilier principal sur lequel repose le domaine de l’intelligence artificielle. De plus, la plupart des composantes des réseaux neuronaux peuvent être représentés comme des matrices. Numpy permet d’utiliser certaines propriétés des matrices afin de paralléliser les calculs menant à l’entraînement du modèle.  De plus,  comme nous le verrons dans la section suivante, Numpy peut être utilisé afin de représenter des images comme des matrices, et donc faciliter les opérations sur chacun des pixels.


\subsection{Matplolib}
\label{\detokenize{explications_librairies:matplolib}}
\sphinxhref{https://matplotlib.org}{Matplotlib} est une librairie de visualisation implémentée dans le langage de programmation Python.


\subsubsection{Historique}
\label{\detokenize{explications_librairies:id8}}
La libraire est un projet à code source ouvert financé par \sphinxhref{https://numfocus.org}{Numfocus}. Déployé depuis plus de 17 ans cite\sphinxcode{\sphinxupquote{wikimatplotlib}},  la librairie permet, tout comme \sphinxcode{\sphinxupquote{Numpy}}, au langage de programmation Python de se rapprocher de l’application Matlab, tout en restant libre de droit.


\subsubsection{Notre utilisation}
\label{\detokenize{explications_librairies:id9}}
La librairie fourni un \sphinxstyleemphasis{API} simple à utiliser permettant de réaliser des graphiques directement dans nos notebooks. Nous utilisons aussi la fonctionnalité permettant de représenter des images comme suit:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{train\PYGZus{}data}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

Ce qui permet d’obtenir la figure suivante:

\sphinxincludegraphics{{plot-demo}.png}

\sphinxcode{\sphinxupquote{train\_data{[}0{]}}} est un \sphinxcode{\sphinxupquote{array}} de pixels, représentés par leur \sphinxcode{\sphinxupquote{grayscale value}}. Nous discuterons plus de ces termes dans la section suivante.




\section{Notions de base}
\label{\detokenize{OCR_SAM:notions-de-base}}\label{\detokenize{OCR_SAM::doc}}

\subsection{Introduction au réseau neuronal}
\label{\detokenize{OCR_SAM:introduction-au-reseau-neuronal}}
Un réseau neuronal est une forme d’intelligence artificielle, qui effectue des prédictions basées sur des valeurs qui sont entrées dans le système, afin d’accomplir une certaine tâche. Le réseau est constitué d’un ensemble de neurones interconnectés et distribués en plusieurs couches.

Chaque neurone possède des paramètres qui peuvent être ajustés, afin d’obtenir des résultats plus fiables. C’est ce qu’on appele l’entrainement.
Le réseau est entrainé à partir d’une base de données, qui contient des valeurs associées à une étiquette, qui consiste de la « réponse » attendue.

Par exemple, un réseau neuronal ayant comme objectif de prédire l’achalandage dans un parc d’amusement pour une journée donnée pourrait recevoir comme intrant la température, le niveau d’ensoleillement ainsi que le pourcentage de précipitation et d’humidité. La base de données serait alors constituée d’une liste ces quatres valeurs enregistrées à chaque jour des dernières années, avec comme étiquette le nombre de clients cette journée\sphinxhyphen{}là. Les réponses du réseau sont comparées aux étiquettes, et les paramètres des neurones sont individuellement modifiés de manière à se rapprocher de la réponse attendue.

\sphinxincludegraphics{{uc}.png}

\sphinxstyleemphasis{Ceci est un exemple simplifié d’un réseau neuronal. Les composantes du schéma seront expliquées en détail dans cette section.}


\subsection{OCR}
\label{\detokenize{OCR_SAM:ocr}}
Le terme OCR, ou ROC en français, signifie « Reconnaissance optique de caractères ». Cela désigne un processus aucours duquel du texte est extrait
d’une image ou d’un document afin d’être transformé en fichier. Pour ce faire, un réseau neuronal reçoit les valeurs des pixels du document de source,
\begin{quote}

Note : La valeur d’un pixel en « grayscale » ou échelle de gris, est un nombre entier
de format 8 bits et peut donc avoir
une valeur comprise entre 0 et 255 (2\textasciicircum{}8 \sphinxhyphen{} 1), où 0 est noir et 255 est blanc.
Un pixel en couleur est représenté sous la forme d’un vecteur de 3 nombres 8
bits, chaque nombre correspondant à une valeur de rouge, vert et bleu. \sphinxcite{zbiblio_commented:hipr2}
\end{quote}

traitées afin de les rendre utilisables par le réseau. Ces données se propagent ensuite vers l’avant
dans le réseau, de couche de neurone en couche de neurone, avant d’aboutir à la couche d’extrants, composée de 10 neurones dans le cas de notre
programme, qui correspondent aux chiffres de 0 à 9. Un de ces neurones de cette couche finale s’active, donnant ainsi le résultat estimé par le réseau.
Ensuite, divers paramètres sont ajustés par un algorithme d’optimisation afin d’augmenter la précision des réponses du réseau.


\subsection{Le neurone}
\label{\detokenize{OCR_SAM:le-neurone}}
Le neurone est l’unité de base d’un réseau neuronal. C’est un noeud parmis le réseau par lequel transitent des valeurs, qui sont modifiées
au passage par un procédé qui sera expliqué plus en détail prochainement, avant d’être envoyées vers les prochains neurones.
Essentiellement, un neurone reçoit une ou des valeurs comme intrant, effectue des opérations sur ces dernières, puis transmet la nouvelle valeur.

La structure d’un neurone est relativement simple. Chaque neurone possède un coefficient, ou un \sphinxstylestrong{poids} \(p\) dans le jargon, associé à chaque \sphinxstylestrong{intrant} \(I\) qu’elle reçoit.
La première opération que la neurone effectue est la somme des produits des intrants fois leur poids. À celà est ajouté un \sphinxstylestrong{biais} \(b\) propre à chaque neurone.
Cette opération peut être représentée par la fonction \$\(Y = \sum_{i=1}^{n} I_i \times p_i + b\)\$, où n correspond au nombre d’intrants.

La dernière opération que les valeurs subissent avant d’être transmises est une fonction d’activation. La fonction d’activation est appliquée à chaque extrant de chaque
neurone de la couche. Les fonctions d’activation, analogues à l’activation
d’un neurone biologique, permettent généralement d’obtenir un extrant compris entre 0 et 1, ou \sphinxhyphen{}1 et 1. Elles ont plusieurs utilités, notamment
pour la modélisation de fonctions non linéeaires, ainsi que pour l’entrainement du réseau, ce qui sera expliqué dans une section ultérieure.

La fonction la plus simple est la

La fonction d’activation la plus utilisée est la fonction Unité Linéaire Rectifiée, ou « ReLU » en anglais (Rectified Linear Unit).
Cette fonction peut être représentée par l’équation :  \$\(
R(x)=
\begin{cases}
 x & \quad \text{si } x \text{ > 0}\\
 0 & \quad \text{si } x \text{ <= 0}
\end{cases}
\)\$

ou encore, \( R(x) = max(0, x)\). Cette fonction est peu demandante à calculer pour l’ordinateur, et se fait très rapidement. De plus, malgré son apparence linéaire,
elle peut être dérivée, ce qui est nécessaire pour pouvoir entrainer le réseau. C’est pour ces raisons que c’est la fonction d’activation la plus répendue.
Elle a toutefois comme désavantage de produire parfois une trop grande quantité de « 0 », ce qui peut entrainer une réaction en chaine, où ces zéros se propagent,
empêchant le bon fonctionnement du réseau. Cette situation est appelée la « mort du réseau ».

Une variation de cette fonction, nommée Leaky ReLU, a été créée afin de tenter de régler ce problème de mort du réseau : \$\( 
L(x)=
\begin{cases}
 x & \quad \text{si } x \text{ > 0}\\
 0,01 \times x & \quad \text{si } x \text{ <= 0}
\end{cases}
\)\$

Ici, les zéros sont remplacés par de très petits nombres négatifs, qui correspondent généralement à x multiplié par le coefficient 0,01.

Une autre fonction commune est la sigmoide. Son équation est : \$\( \phi(x) = 
                                                                    \frac{1}{1 + e^{-x}}
                                                                    \)\$
La fonction retourne 0 lorsque x tend vers l’infini négatif, et 1 lorsque x tend vers l’infini positif. Cette fonction a comme avantage de


\subsection{Couches de neurones}
\label{\detokenize{OCR_SAM:couches-de-neurones}}
Comme mentionné précedemment, les neurones sont organisés en couches. Il y a 3 types de couches différentes. La première est la couche des intrants, dans laquelle
les données sont rentrées dans le réseau. Dans le cas de notre programme, où les intrants sont des images de format 28x28, la première couche est composée de 784 (28*28 = 784) neurones recevant chacun la valeur en echelle de gris  d’un pixel de l’image. Plus concrètement, ces images sont des matrices \(M_{28}\), qui se font vectoriser


\section{L’entrainement d’un système neuronal}
\label{\detokenize{OCR_SAM:l-entrainement-d-un-systeme-neuronal}}
L’entrainement d’un réseau à l’aide d’une certaine base de données (donnée d’entrainement) permet à celui\sphinxhyphen{}ci de prédire le résultat d’une autre base donnée. En effet, le but d’un réseau neuronal est de réduire l’erreur de l’entrainement ainsi que la différence entre l’erreur des données entrainées et l’erreur des données de test soient petites. Lorsque le réseau est sous\sphinxhyphen{}entrainé, le réseau de sera pas précis lors de ces résultats. Cependant, lorsque le réseau est sur\sphinxhyphen{}entrainé, celui\sphinxhyphen{}ci va prendre en compte tout le bruit des données. Ce bruit peut être, par exemple, le fait de prendre en compte les imperfections d’une image, reconnaitre seulement certains styles d’écriture, etc. Cela a comme impact d’augmenter l’erreur lorsque le système est exposé à une nouvelle base de données.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{overfitting}.png}
\caption{Graphiques représentant l’effet de l’entrainement du réseau de neurone}\label{\detokenize{OCR_SAM:overfitting}}\end{figure}

L’entrainement d’un réseau neuronal s’effectue à l’inverse. Visuellement, l’entrainement et l’ajustement des différents paramètres se font de la droite vers la gauche. Ce principe, appelé « backpropagation », va être expliqué à l’aide quelques démonstrations mathématiques complémentées par quelques explications écrites.


\subsection{Fonction d’erreur}
\label{\detokenize{OCR_SAM:fonction-d-erreur}}
Une fonction d’erreur est une fonction permettant de connaitre la précision des résultats des extrants de la dernière couche. Il peut y avoir plusieurs fonctions d’erreur. En voici un exemple:

\$\(E_{SS}=1/2\sum_{i=1}^nE_i^2 \)\$ \sphinxstylestrong{(1.1)}

\$\(E_{SS}=1/2\sum_{i=1}^nE_i^2 \)\$ \sphinxstylestrong{(1.2)}

où \(E_{SS}\)= « error sum of square ». Cela est tout simplement une de plusieurs fonctions d’erreur.

\$\(E_i =|{t_i-I_i}|\)\$ \sphinxstylestrong{(1.3)}

où \(E_i\) correspond à l’erreur d’un neurone de la dernière couche (extrant). \(I_i\) correspond à la valeur numérique d’un extrant et \(t_i\) correspond à la valeur désirée provenant de la base de données fournies.

Combiner les deux équations permet d’obtenir:

\$\(E=1/2\sum_{i=1}^n({T_i-Y_i})^2 \)\$ \sphinxstylestrong{(1.4)}


\subsection{Transmition de l’information}
\label{\detokenize{OCR_SAM:transmition-de-l-information}}\begin{quote}

Note: Afin de simplifier les explications, ces dernières seront faites en utilisant un réseau neuronal ayant seulement 1 neurone par couche.
\end{quote}

D’abord, il faut comprendre comment le réseau transmet son information de cellules en cellule. En effet, un neurone ayant contenant une certaine valeur \(Y\) transmet cette dernière à tous les autres neurones de la prochaine couche. Cependant, ces transmitions n’ont pas toutes les mêmes poids. Ces poids \(p\) diffèrent afin de favoriser certaines activations et en défavoriser d’autres. Chaque liaison entre chaque neurone possède un poid propre à chacune. Ces derniers sont multipliés avec l’extrant de la neurone en précédentes.

\$\(Y_{i} = Y_{i-1}\times p_{i}\)\$\sphinxstylestrong{(2.0)}

où \(p_{i}\) correspond au poid de la neurone de la couche i

Ensuite, un biais \(b\) est additionné ou soustrait au résultat précédent

\$\(Y_i = Y_{i-1}\times p_{i} + b_i\)\$ \sphinxstylestrong{(2.1)}

où \(b_i\) correspond au biais de la neurone de la couche i.

Finalement, une fonction d’activation \(a\) est ajoutée au reste de la formule. L’utilité et le fonctionnement de la fonction d’activation sera expliqué en détail plus loin.

\$\(Y_i = a\times(Y_{i-1}\times p_{i} + b_i)\)\$ \sphinxstylestrong{(2.2)}


\subsection{\sphinxstyleemphasis{Back propagation}}
\label{\detokenize{OCR_SAM:back-propagation}}
L’objectif est de comprendre comment le poids et le biais doit être ajuster en débutant de la fonction d’erreur et d’activation.

Dabord, en utilisant la formule de base de transmission d’un neurone (sans le biais) :

\(Y = \sum_{i=1}^{n} I_i \times p_i \)

Il est possible de comprendre comment le changement d’une variable impact une autre. Les dérivés seront donc utilisées afin de démontrer ce principe.
\begin{equation*}
\begin{split}\frac{dY}{dI_i}=\frac{dY}{dI_i}\sum_{i=1}^{n} I_i \times p_{ji} 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}\frac{dY}{dI_i} = p_i\end{split}
\end{equation*}\begin{equation*}
\begin{split}\frac{dY}{dp_i} = I_i\end{split}
\end{equation*}
Cela veut donc dire que le poid influence le résultat de l’extrant et que l’intrant influence le résultat de l’extrant.

En utlisant la formule (1.4) et le concept de dérivée partielle, il est possible de comprendre l’impact d’un changement de la valeur de l’intrant \(I_i\) sur l’erreur:
\begin{equation*}
\begin{split}\frac{dE}{dI_i} =  (2/2)(t_i - I_i)(-1) \end{split}
\end{equation*}\begin{equation*}
\begin{split}\frac{dE}{dI_i}= -(t_i-I_i)\end{split}
\end{equation*}
Maintenant, il faut calculer la dérivation de la fonction d’activation.
La fonction sigmoïde sera utilisée pour cet exemple.
\begin{equation*}
\begin{split}a = \frac{1}{1 + e^{-Y}} =(1+e^{-Y})^{-1}\end{split}
\end{equation*}\begin{equation*}
\begin{split}\frac{da}{dY} = -1 (-e^{-Y})(1+e^{-Y})^{-2} \end{split}
\end{equation*}\begin{equation*}
\begin{split}= \frac{e^{-Y}}{(1+e^{-Y})^2} \end{split}
\end{equation*}\begin{equation*}
\begin{split}= \frac{1}{(1+e^{-Y})}\times\frac{e^{-Y}}{(1+e^{-Y})} \end{split}
\end{equation*}\begin{equation*}
\begin{split}= a \times \frac{e^{-Y}}{(1+e^{-Y})}\end{split}
\end{equation*}\begin{equation*}
\begin{split}= a \times \frac{1+e^{-Y}-1}{(1+e^{-Y})} \end{split}
\end{equation*}\begin{equation*}
\begin{split}= a \times (\frac{(1+e^{-Y})}{(1+e^{-Y})} + \frac{-1}{(1+e^{-Y})})\end{split}
\end{equation*}\begin{equation*}
\begin{split}\frac{da}{dY}= a \times (1-a)\end{split}
\end{equation*}
Maintenant il est possible, à l’aide de la règle de dérivation en chaine, de trouver l’impact qu’a \(Y\) sur l’erreur \(E\). Dans cet exemple, \(I_i = a \) puisque la fonction d’activation été appliquée au neurone en question.
\begin{equation*}
\begin{split}\frac{dE}{dY_i} = \frac{dE}{dI_i} \times \frac{dI_i}{dY_i}\end{split}
\end{equation*}\begin{equation*}
\begin{split}= \frac{dE}{dI_i} \times \frac{da}{dY_i}\end{split}
\end{equation*}\begin{align*}\!\begin{aligned}
=-(t_i - I_i)  I_i (1- I_i)$$  __(3.0)__\\
Ensuite il est possible de calculer la dérivation de l'erreur en fonction du poid $p_{ji}$ d'une liaison entre deux neurones.\\
$$\frac{dE}{dp_{ji}} =\frac{dE}{dY_i} \times \frac{dY_i}{dp_{ji}}\\
\end{aligned}\end{align*}\begin{equation*}
\begin{split}= (-(t_i - I_i) \times I_i\times (1- I_i))\times I_i\end{split}
\end{equation*}\begin{align*}\!\begin{aligned}
= -I_i I_j (1-I_i)(t_i-I_i)$$__(4.0)__\\
Cette équation signifie que le changement de l'erreur influence le poid et cette influence correspond à l'extrant d'un neurone négatif multiplié par l'extrant du neurone précédent et ce tout est multplié par 1 moins la valeur du neurone. À ce résultat est multiplié la valeur de l'erreur soit : $(t_i-I_i)$
L'équation 3.0 sera représenté par la variable:  $\Delta p$\\
Le concept de "backpropagation" se résume donc a:\\
$$p_{ji} = p_{ji} + \Delta p\\
\end{aligned}\end{align*}
Le poids d’un neurone change légèrement en additionnant un \(\Delta p\)  positif ou négatif. Ce changement est fait avec une plus grande importance plus le neurone est proche de la couche des extrants. Cela est dû au fait que l’apprentissage commence par la couche finale pour enfin se rendre jusqu’à la couche débutant le système neuronal. Les premiers ajustements, donc ceux des couches plus proches de la fin, sont plus importants. Les couches se situant plus au début du réseau vont plutôt avoir de petits changements à leur poids puisque rendu à l’ajustement de dce dernier, l’erreur est déja considérablement réduite. Ce concept se nomme descente de gradient stochastique.


\subsection{Origine du biais}
\label{\detokenize{OCR_SAM:origine-du-biais}}
Certains problèmes peuvent survenir avec le concept de descente de gradiant dans un réseau neuronal. En effet, lorsqu’une couche « n’apprend plus » ou, en d’autres mots, lorsque le poids ne varie plus, on assiste a un problème se nommant la disparition du gradiant. Cela est un problème pour le réseau puisque le tout l’entrainement se fait uniquement dans les dernières couches. Un autre problème est que le gradiant dans une fonction de coût telle une sigoïde, le gradient se situe uniquement au milieu de la fonction comme le montre le graphique ci\sphinxhyphen{}dessous.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{tanh}.png}
\caption{Fonction sigmoïde}\label{\detokenize{OCR_SAM:tanh}}\end{figure}

En effet, les extrémités de la fonction forment un plateau. Il n’y a donc pas de changement possible puisque soit l’intrant est multiplié par 1, ce qui ne change pas le résultat, ou bien soit le résultat est multiplié par 0 ce qui rend la valeurr nul et cela est néfaste pour un réseau neuronal. En effet, une valeur égale a 0 empêche l’entrainement du réseau puisque peut importe la variation du poid, \(0\times p\) sera toujours être égale à 0. C’est pour remédier à cette erreur qu’un biais est ajouté à la fonction.
\begin{equation*}
\begin{split}Y =\sum_{i=1}^{n} I_i \times p_i + b\end{split}
\end{equation*}
L’ajout de ce biais va permettre de conserver un apprentissage même lorsque la valeur d’un neurone est figée à 0.


\section{Première version de notre modèle}
\label{\detokenize{OCR_SAM:premiere-version-de-notre-modele}}
\sphinxstylestrong{Liens utiles}

https://www.pyimagesearch.com/2020/08/24/ocr\sphinxhyphen{}handwriting\sphinxhyphen{}recognition\sphinxhyphen{}with\sphinxhyphen{}opencv\sphinxhyphen{}keras\sphinxhyphen{}and\sphinxhyphen{}tensorflow/

https://www.pyimagesearch.com/2020/08/17/ocr\sphinxhyphen{}with\sphinxhyphen{}keras\sphinxhyphen{}tensorflow\sphinxhyphen{}and\sphinxhyphen{}deep\sphinxhyphen{}learning/

https://www.tensorflow.org/tutorials/keras/classification


\subsection{Les librairies nécessaires}
\label{\detokenize{OCR_SAM:les-librairies-necessaires}}
Afin de réaliser ce projet dans des temps raisonnables, nous utilisons des
outils des des données réalisés par des organisations réputées comme Google,
\sphinxhref{https://numpy.org/}{NumPy} et la \sphinxhref{https://matplotlib.org/}{Matplotlib}
development team.


\subsubsection{Tensorflow}
\label{\detokenize{OCR_SAM:tensorflow}}
C’est quoi tensorflow


\paragraph{Keras}
\label{\detokenize{OCR_SAM:keras}}
C’est quoi keras

https://www.tensorflow.org/api\_docs/python/tf/keras


\paragraph{MNIST}
\label{\detokenize{OCR_SAM:mnist}}
C’est quoi le MNIST


\subsubsection{Numpy}
\label{\detokenize{OCR_SAM:numpy}}
C’est quoi numpy et comment est ce qu’on l’utilise


\subsubsection{Matplotlib}
\label{\detokenize{OCR_SAM:matplotlib}}
C’est quoi matplotlib est comment est ce qu’on l’utilise

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} TensorFlow and tf.keras}
\PYG{k+kn}{import} \PYG{n+nn}{tensorflow} \PYG{k}{as} \PYG{n+nn}{tf}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow} \PYG{k+kn}{import} \PYG{n}{keras}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{mnist}

\PYG{c+c1}{\PYGZsh{} Helper libraries}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{tf}\PYG{o}{.}\PYG{n}{\PYGZus{}\PYGZus{}version\PYGZus{}\PYGZus{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{\PYGZlt{}}\PYG{n}{ipython}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{input}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{222}\PYG{n}{b9a9d3278}\PYG{o}{\PYGZgt{}} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{1} \PYG{c+c1}{\PYGZsh{} TensorFlow and tf.keras}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{2} \PYG{k+kn}{import} \PYG{n+nn}{tensorflow} \PYG{k}{as} \PYG{n+nn}{tf}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{3} \PYG{k+kn}{from} \PYG{n+nn}{tensorflow} \PYG{k+kn}{import} \PYG{n}{keras}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{4} \PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{mnist}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{5} 

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}tensorflow\PYGZsq{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{type}\PYG{p}{(}\PYG{n}{mnist}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
numpy.ndarray
\end{sphinxVerbatim}


\subsection{Chargement du MNIST data}
\label{\detokenize{OCR_SAM:chargement-du-mnist-data}}
La cellule ci\sphinxhyphen{}dessous permet de séparer la base de données MNIST, de tensorFlow, en différentes variables(train\_data, train\_label, test\_date, test\_labels) grâce à la fonction mnist.load\_data()

train\_data contient des images 28X28 pixels d’un chiffre écrit à la main qui serviront à entrainer le réseau neuronal

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{train\PYGZus{}data}\PYG{p}{)}
\end{sphinxVerbatim}

train\_labels contient le chiffre associé à la réponse attendue lors de l’entrainement

test\_data train\_data contient des images 28X28 pixels d’un chiffre écrit à la main qui serviront à tester la précision du réseau neuronal

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{toto}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
toto
\end{sphinxVerbatim}

test\_labels contient le chiffre associé à la réponse attendue lors des tests de précisions

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{(}\PYG{p}{(}\PYG{n}{train\PYGZus{}data}\PYG{p}{,} \PYG{n}{train\PYGZus{}labels}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{n}{test\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}labels}\PYG{p}{)}\PYG{p}{)} \PYG{o}{=} \PYG{n}{mnist}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{num\PYGZus{}data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{vstack}\PYG{p}{(}\PYG{p}{[}\PYG{n}{train\PYGZus{}data}\PYG{p}{,} \PYG{n}{test\PYGZus{}data}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{num\PYGZus{}labels} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{hstack}\PYG{p}{(}\PYG{p}{[}\PYG{n}{train\PYGZus{}labels}\PYG{p}{,} \PYG{n}{test\PYGZus{}labels}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{google}\PYG{n+nn}{.}\PYG{n+nn}{colab} \PYG{k+kn}{import} \PYG{n}{drive}
\PYG{n}{drive}\PYG{o}{.}\PYG{n}{mount}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/content/drive}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

La fonction .shape permet de retourner la forme d’une matrice. La réponse obtenue signifie que train\_data contient une liste de 60000 matrice de pixel 28X28.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{train\PYGZus{}data}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(60000, 28, 28)
\end{sphinxVerbatim}

La fonction len() retourne le nombre d’unité de la variable de type liste. La réponse obtenue signifie qu’il y a 60000 réponses attendue aux 60000 matrices de pixels.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{train\PYGZus{}labels}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
60000
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{train\PYGZus{}labels}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)
\end{sphinxVerbatim}

La réponse obtenue signifie que train\_data contient une liste de 10000 matrice de pixel 28X28.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{test\PYGZus{}data}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(10000, 28, 28)
\end{sphinxVerbatim}


\subsection{Prétraitement}
\label{\detokenize{OCR_SAM:pretraitement}}
Utilisation de la librairie mathplotlib
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
plt.figure():Permet de créer un nouveau graphique vide

\item {} 
plt.imshow():Transforme une matrice X par X de pixel. Dans notre cas il s’agit d’une matrice 28x28 de pixels qui représente un chiffre dessiné à la main.

\item {} 
plt.colorbar(): Ajoute une légende de couleur au graphique. Dans notre cas, la légence va de 0 à 255 ce qui représente la valeur d’un pixel dans un « greyscale ».

\item {} 
plt.grid(): Ajoute ou enlève un grillage

\item {} 
plt.show(): Affiche toutes les figures présentent dans la mémoire.

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{train\PYGZus{}data}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{colorbar}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{grid}\PYG{p}{(}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{OCR_SAM_29_0}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{train\PYGZus{}labels}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
5
\end{sphinxVerbatim}

Sachant que la valeur maximal d’un pixel est de 255. Toutes les valeurs sont divisées par 255 afin d’obtenir des résultats entre 0 et 1.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{train\PYGZus{}images} \PYG{o}{=} \PYG{n}{train\PYGZus{}data} \PYG{o}{/} \PYG{l+m+mf}{255.0}
\PYG{n}{test\PYGZus{}images} \PYG{o}{=} \PYG{n}{test\PYGZus{}data} \PYG{o}{/} \PYG{l+m+mf}{255.0}
\end{sphinxVerbatim}

Crée les 25 premières images en noir et blanc de la matrice train\_data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{25}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplot}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{n}{i}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xticks}\PYG{p}{(}\PYG{p}{[}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{yticks}\PYG{p}{(}\PYG{p}{[}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{grid}\PYG{p}{(}\PYG{k+kc}{False}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{train\PYGZus{}images}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{n}{plt}\PYG{o}{.}\PYG{n}{cm}\PYG{o}{.}\PYG{n}{binary}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{n}{train\PYGZus{}labels}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{OCR_SAM_34_0}.png}

keras.sequential() permet, en fournissant une liste de couche, de créer un sytème neuronal(model).
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
keras.layers.Flatten(input\_shape=(28, 28) est la première couche du sytème neuronal. Celle\sphinxhyphen{}ci est composé des intrants d’une liste. La fonction transforme la matrice de pixel de 28x28 en une liste de 784 pixels.

\item {} 
keras.layers.Dense(128, activation=”relu”) est la deuxième couche du système neuronal. Celle\sphinxhyphen{}ci, grâce à la fonction .Dense est densément connecté à la première couche. Cela signifie que chacune des neurones de la première couche est connectée à chacune des neuronnes de la deuxième couche.

\item {} 
keras.layers.Dense(10) est la troixième couche et dernière du réseau neuronal. Celle\sphinxhyphen{}ci est aussi densément connectée à la deuxème couche. Les résulats des 10 neurones finales sont les extrants.

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{keras}\PYG{o}{.}\PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{[}
    \PYG{n}{keras}\PYG{o}{.}\PYG{n}{layers}\PYG{o}{.}\PYG{n}{Flatten}\PYG{p}{(}\PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{28}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{keras}\PYG{o}{.}\PYG{n}{layers}\PYG{o}{.}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{128}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{relu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{keras}\PYG{o}{.}\PYG{n}{layers}\PYG{o}{.}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}
\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

model.compile() ajoute des réglages au model avant de l’entrainer.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
optimizer = “adam”: ajoute un algorithme qui indique au réseau comment traiter les données et le résutlat de la fonction de loss.

\item {} 
loss = tf.keras.losses.SparseCategoricalCrossentropy(from\_logits=True): Montre la précision du model. Plus le résultat, est bas, plus le model est précis.

\item {} 
metrics = {[}“accuracy”{]}: Permet de choisir la façon de contrôler l’entrainement et les test du réseau neuronal. Pour notre cas, nous utilisons la fonction accuracy qui correspond au bon nombre d’images prédites sur le nombre total de prédictions.

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{adam}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
              \PYG{n}{loss}\PYG{o}{=}\PYG{n}{tf}\PYG{o}{.}\PYG{n}{keras}\PYG{o}{.}\PYG{n}{losses}\PYG{o}{.}\PYG{n}{SparseCategoricalCrossentropy}\PYG{p}{(}\PYG{n}{from\PYGZus{}logits}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{,}
              \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{accuracy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

model.fit(train\_images, train\_labels, epochs=10): prend les données de train\_images (60000, 28, 28), fait des prédictions sur le chiffre écrit et les compares avec les réponses de train\_labels (60000) dans le but d’améliorer la précision du modèle apres chaque « epochs ». Le chiffre associé à « epochs » correspond au nombre d’entrainement effectué sur le modèle.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{train\PYGZus{}images}\PYG{p}{,} \PYG{n}{train\PYGZus{}labels}\PYG{p}{,} \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Epoch 1/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.2568 \PYGZhy{} accuracy: 0.9283
Epoch 2/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.1147 \PYGZhy{} accuracy: 0.9660
Epoch 3/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.0791 \PYGZhy{} accuracy: 0.9764
Epoch 4/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.0580 \PYGZhy{} accuracy: 0.9824
Epoch 5/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.0455 \PYGZhy{} accuracy: 0.9859
Epoch 6/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.0350 \PYGZhy{} accuracy: 0.9892
Epoch 7/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.0286 \PYGZhy{} accuracy: 0.9908
Epoch 8/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.0236 \PYGZhy{} accuracy: 0.9926
Epoch 9/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.0198 \PYGZhy{} accuracy: 0.9939
Epoch 10/10
1875/1875 [==============================] \PYGZhy{} 3s 2ms/step \PYGZhy{} loss: 0.0148 \PYGZhy{} accuracy: 0.9956
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}tensorflow.python.keras.callbacks.History at 0x7fe4f5d81e48\PYGZgt{}
\end{sphinxVerbatim}

Représente la précision du système neuronal lorsqu’il soumit à des données différentes (test\_data, test\_labels).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{test\PYGZus{}loss}\PYG{p}{,} \PYG{n}{test\PYGZus{}acc} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{evaluate}\PYG{p}{(}\PYG{n}{test\PYGZus{}images}\PYG{p}{,}  \PYG{n}{test\PYGZus{}labels}\PYG{p}{,} \PYG{n}{verbose}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Test accuracy:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{test\PYGZus{}acc}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
313/313 \PYGZhy{} 0s \PYGZhy{} loss: 0.0747 \PYGZhy{} accuracy: 0.9804

Test accuracy: 0.980400025844574
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{summary}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Model: \PYGZdq{}sequential\PYGZdq{}
\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}
Layer (type)                 Output Shape              Param \PYGZsh{}   
=================================================================
flatten (Flatten)            (None, 784)               0         
\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}
dense (Dense)                (None, 128)               100480    
\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}
dense\PYGZus{}1 (Dense)              (None, 10)                1290      
=================================================================
Total params: 101,770
Trainable params: 101,770
Non\PYGZhy{}trainable params: 0
\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{probability\PYGZus{}model} \PYG{o}{=} \PYG{n}{tf}\PYG{o}{.}\PYG{n}{keras}\PYG{o}{.}\PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{[}\PYG{n}{model}\PYG{p}{,} 
                                         \PYG{n}{tf}\PYG{o}{.}\PYG{n}{keras}\PYG{o}{.}\PYG{n}{layers}\PYG{o}{.}\PYG{n}{Softmax}\PYG{p}{(}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{predictions} \PYG{o}{=} \PYG{n}{probability\PYGZus{}model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{test\PYGZus{}images}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{predictions}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([1.33047600e\PYGZhy{}08, 2.02930346e\PYGZhy{}11, 1.42667460e\PYGZhy{}07, 3.34045399e\PYGZhy{}05,
       1.87632367e\PYGZhy{}14, 5.29390087e\PYGZhy{}10, 8.63112412e\PYGZhy{}17, 9.99945879e\PYGZhy{}01,
       1.26384725e\PYGZhy{}08, 2.05938213e\PYGZhy{}05], dtype=float32)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{predictions}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
7
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{test\PYGZus{}labels}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
7
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{plot\PYGZus{}image}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{predictions\PYGZus{}array}\PYG{p}{,} \PYG{n}{true\PYGZus{}label}\PYG{p}{,} \PYG{n}{img}\PYG{p}{)}\PYG{p}{:}
  \PYG{n}{true\PYGZus{}label}\PYG{p}{,} \PYG{n}{img} \PYG{o}{=} \PYG{n}{true\PYGZus{}label}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{grid}\PYG{p}{(}\PYG{k+kc}{False}\PYG{p}{)}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xticks}\PYG{p}{(}\PYG{p}{[}\PYG{p}{]}\PYG{p}{)}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{yticks}\PYG{p}{(}\PYG{p}{[}\PYG{p}{]}\PYG{p}{)}

  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{n}{plt}\PYG{o}{.}\PYG{n}{cm}\PYG{o}{.}\PYG{n}{binary}\PYG{p}{)}

  \PYG{n}{predicted\PYGZus{}label} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{predictions\PYGZus{}array}\PYG{p}{)}
  \PYG{k}{if} \PYG{n}{predicted\PYGZus{}label} \PYG{o}{==} \PYG{n}{true\PYGZus{}label}\PYG{p}{:}
    \PYG{n}{color} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{blue}\PYG{l+s+s1}{\PYGZsq{}}
  \PYG{k}{else}\PYG{p}{:}
    \PYG{n}{color} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{red}\PYG{l+s+s1}{\PYGZsq{}}

  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s2}{ }\PYG{l+s+si}{\PYGZob{}:2.0f\PYGZcb{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{ (}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s2}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{predicted\PYGZus{}label}\PYG{p}{,}
                                \PYG{l+m+mi}{100}\PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{n}{predictions\PYGZus{}array}\PYG{p}{)}\PYG{p}{,}
                                \PYG{n}{true\PYGZus{}label}\PYG{p}{)}\PYG{p}{,}
                                \PYG{n}{color}\PYG{o}{=}\PYG{n}{color}\PYG{p}{)}

\PYG{k}{def} \PYG{n+nf}{plot\PYGZus{}value\PYGZus{}array}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{predictions\PYGZus{}array}\PYG{p}{,} \PYG{n}{true\PYGZus{}label}\PYG{p}{)}\PYG{p}{:}
  \PYG{n}{true\PYGZus{}label} \PYG{o}{=} \PYG{n}{true\PYGZus{}label}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{grid}\PYG{p}{(}\PYG{k+kc}{False}\PYG{p}{)}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xticks}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{)}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{yticks}\PYG{p}{(}\PYG{p}{[}\PYG{p}{]}\PYG{p}{)}
  \PYG{n}{thisplot} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{bar}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{,} \PYG{n}{predictions\PYGZus{}array}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZsh{}777777}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylim}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
  \PYG{n}{predicted\PYGZus{}label} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{predictions\PYGZus{}array}\PYG{p}{)}

  \PYG{n}{thisplot}\PYG{p}{[}\PYG{n}{predicted\PYGZus{}label}\PYG{p}{]}\PYG{o}{.}\PYG{n}{set\PYGZus{}color}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{red}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
  \PYG{n}{thisplot}\PYG{p}{[}\PYG{n}{true\PYGZus{}label}\PYG{p}{]}\PYG{o}{.}\PYG{n}{set\PYGZus{}color}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{blue}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{i} \PYG{o}{=} \PYG{l+m+mi}{0}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplot}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}image}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{predictions}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{test\PYGZus{}labels}\PYG{p}{,} \PYG{n}{test\PYGZus{}images}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplot}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}value\PYGZus{}array}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{predictions}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,}  \PYG{n}{test\PYGZus{}labels}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{OCR_SAM_50_0}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{i} \PYG{o}{=} \PYG{l+m+mi}{12}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplot}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}image}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{predictions}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{test\PYGZus{}labels}\PYG{p}{,} \PYG{n}{test\PYGZus{}images}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplot}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{plot\PYGZus{}value\PYGZus{}array}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{predictions}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,}  \PYG{n}{test\PYGZus{}labels}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{OCR_SAM_51_0}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot the first X test images, their predicted labels, and the true labels.}
\PYG{c+c1}{\PYGZsh{} Color correct predictions in blue and incorrect predictions in red.}
\PYG{n}{num\PYGZus{}rows} \PYG{o}{=} \PYG{l+m+mi}{5}
\PYG{n}{num\PYGZus{}cols} \PYG{o}{=} \PYG{l+m+mi}{3}
\PYG{n}{num\PYGZus{}images} \PYG{o}{=} \PYG{n}{num\PYGZus{}rows}\PYG{o}{*}\PYG{n}{num\PYGZus{}cols}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{num\PYGZus{}cols}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{num\PYGZus{}rows}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{num\PYGZus{}images}\PYG{p}{)}\PYG{p}{:}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplot}\PYG{p}{(}\PYG{n}{num\PYGZus{}rows}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{num\PYGZus{}cols}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{i}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}
  \PYG{n}{plot\PYGZus{}image}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{predictions}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{test\PYGZus{}labels}\PYG{p}{,} \PYG{n}{test\PYGZus{}images}\PYG{p}{)}
  \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplot}\PYG{p}{(}\PYG{n}{num\PYGZus{}rows}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{num\PYGZus{}cols}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{i}\PYG{o}{+}\PYG{l+m+mi}{2}\PYG{p}{)}
  \PYG{n}{plot\PYGZus{}value\PYGZus{}array}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{predictions}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{test\PYGZus{}labels}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{OCR_SAM_52_0}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Grab an image from the test dataset.}
\PYG{n}{img} \PYG{o}{=} \PYG{n}{test\PYGZus{}images}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{img}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(28, 28)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Add the image to a batch where it\PYGZsq{}s the only member.}
\PYG{n}{img} \PYG{o}{=} \PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{expand\PYGZus{}dims}\PYG{p}{(}\PYG{n}{img}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{img}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(1, 28, 28)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{predictions\PYGZus{}single} \PYG{o}{=} \PYG{n}{probability\PYGZus{}model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{predictions\PYGZus{}single}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
[[1.0413674e\PYGZhy{}12 2.4460157e\PYGZhy{}08 1.0000000e+00 1.2474424e\PYGZhy{}09 1.9520718e\PYGZhy{}24
  2.0112491e\PYGZhy{}10 8.8550174e\PYGZhy{}12 1.1677123e\PYGZhy{}19 1.9958409e\PYGZhy{}10 1.3060724e\PYGZhy{}16]]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plot\PYGZus{}value\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{predictions\PYGZus{}single}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{l+m+mi}{7}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{l+m+mi}{9}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xticks}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{l+m+mi}{7}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{l+m+mi}{9}\PYG{p}{]}\PYG{p}{,} \PYG{n}{rotation}\PYG{o}{=}\PYG{l+m+mi}{45}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}The labels are wrong}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{OCR_SAM_56_0}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{predictions\PYGZus{}single}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
2
\end{sphinxVerbatim}


\subsection{Testing it on my own images}
\label{\detokenize{OCR_SAM:testing-it-on-my-own-images}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{display}\PYG{p}{,} \PYG{n}{Javascript}
\PYG{k+kn}{from} \PYG{n+nn}{google}\PYG{n+nn}{.}\PYG{n+nn}{colab}\PYG{n+nn}{.}\PYG{n+nn}{output} \PYG{k+kn}{import} \PYG{n}{eval\PYGZus{}js}
\PYG{k+kn}{from} \PYG{n+nn}{base64} \PYG{k+kn}{import} \PYG{n}{b64decode}

\PYG{k}{def} \PYG{n+nf}{take\PYGZus{}photo}\PYG{p}{(}\PYG{n}{filename}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{photo.jpg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{quality}\PYG{o}{=}\PYG{l+m+mf}{0.8}\PYG{p}{)}\PYG{p}{:}
  \PYG{n}{js} \PYG{o}{=} \PYG{n}{Javascript}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}\PYGZsq{}\PYGZsq{}}
\PYG{l+s+s1}{    async function takePhoto(quality) }\PYG{l+s+s1}{\PYGZob{}}
\PYG{l+s+s1}{      const div = document.createElement(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{div}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{);}
\PYG{l+s+s1}{      const capture = document.createElement(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{button}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{);}
\PYG{l+s+s1}{      capture.textContent = }\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Capture}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{;}
\PYG{l+s+s1}{      div.appendChild(capture);}

\PYG{l+s+s1}{      const video = document.createElement(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{video}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{);}
\PYG{l+s+s1}{      video.style.display = }\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{block}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{;}
\PYG{l+s+s1}{      const stream = await navigator.mediaDevices.getUserMedia(}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{video: true\PYGZcb{});}

\PYG{l+s+s1}{      document.body.appendChild(div);}
\PYG{l+s+s1}{      div.appendChild(video);}
\PYG{l+s+s1}{      video.srcObject = stream;}
\PYG{l+s+s1}{      await video.play();}

\PYG{l+s+s1}{      // Resize the output to fit the video element.}
\PYG{l+s+s1}{      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);}

\PYG{l+s+s1}{      // Wait for Capture to be clicked.}
\PYG{l+s+s1}{      await new Promise((resolve) =\PYGZgt{} capture.onclick = resolve);}

\PYG{l+s+s1}{      const canvas = document.createElement(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{canvas}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{);}
\PYG{l+s+s1}{      canvas.width = video.videoWidth;}
\PYG{l+s+s1}{      canvas.height = video.videoHeight;}
\PYG{l+s+s1}{      canvas.getContext(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{2d}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{).drawImage(video, 0, 0);}
\PYG{l+s+s1}{      stream.getVideoTracks()[0].stop();}
\PYG{l+s+s1}{      div.remove();}
\PYG{l+s+s1}{      return canvas.toDataURL(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{image/jpeg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{, quality);}
\PYG{l+s+s1}{    \PYGZcb{}}
\PYG{l+s+s1}{    }\PYG{l+s+s1}{\PYGZsq{}\PYGZsq{}\PYGZsq{}}\PYG{p}{)}
  \PYG{n}{display}\PYG{p}{(}\PYG{n}{js}\PYG{p}{)}
  \PYG{n}{data} \PYG{o}{=} \PYG{n}{eval\PYGZus{}js}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{takePhoto(}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{quality}\PYG{p}{)}\PYG{p}{)}
  \PYG{n}{binary} \PYG{o}{=} \PYG{n}{b64decode}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
  \PYG{k}{with} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{filename}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{wb}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} \PYG{k}{as} \PYG{n}{f}\PYG{p}{:}
    \PYG{n}{f}\PYG{o}{.}\PYG{n}{write}\PYG{p}{(}\PYG{n}{binary}\PYG{p}{)}
  \PYG{k}{return} \PYG{n}{filename}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{IPython}\PYG{n+nn}{.}\PYG{n+nn}{display} \PYG{k+kn}{import} \PYG{n}{Image}
\PYG{k}{try}\PYG{p}{:}
  \PYG{n}{filename} \PYG{o}{=} \PYG{n}{take\PYGZus{}photo}\PYG{p}{(}\PYG{p}{)}
  \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Saved to }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{filename}\PYG{p}{)}\PYG{p}{)}
  
  \PYG{c+c1}{\PYGZsh{} Show the image which was just taken.}
  \PYG{n}{display}\PYG{p}{(}\PYG{n}{Image}\PYG{p}{(}\PYG{n}{filename}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{except} \PYG{n+ne}{Exception} \PYG{k}{as} \PYG{n}{err}\PYG{p}{:}
  \PYG{c+c1}{\PYGZsh{} Errors will be thrown if the user does not have a webcam or if they do not}
  \PYG{c+c1}{\PYGZsh{} grant the page permission to access it.}
  \PYG{n+nb}{print}\PYG{p}{(}\PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{err}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}IPython.core.display.Javascript object\PYGZgt{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{imutils}
\PYG{k+kn}{import} \PYG{n+nn}{cv2}
\PYG{k+kn}{from} \PYG{n+nn}{google}\PYG{n+nn}{.}\PYG{n+nn}{colab}\PYG{n+nn}{.}\PYG{n+nn}{patches} \PYG{k+kn}{import} \PYG{n}{cv2\PYGZus{}imshow}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k+kn}{import} \PYG{n}{pyplot} \PYG{k}{as} \PYG{n}{plt}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{image} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{imread}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{photo.jpg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{resized\PYGZus{}image} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{resize}\PYG{p}{(}\PYG{n}{image}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{28}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{gray} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{cvtColor}\PYG{p}{(}\PYG{n}{resized\PYGZus{}image}\PYG{p}{,} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{COLOR\PYGZus{}RGB2GRAY}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} blurred = cv2.GaussianBlur(gray, (5, 5), 0)}
\PYG{p}{(}\PYG{n}{thresh}\PYG{p}{,} \PYG{n}{blackAndWhiteImage}\PYG{p}{)} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{threshold}\PYG{p}{(}\PYG{n}{gray}\PYG{p}{,} \PYG{l+m+mi}{110}\PYG{p}{,} \PYG{l+m+mi}{255}\PYG{p}{,} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{THRESH\PYGZus{}BINARY}\PYG{p}{)}
\PYG{n}{imagem} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{bitwise\PYGZus{}not}\PYG{p}{(}\PYG{n}{blackAndWhiteImage}\PYG{p}{)}
\PYG{n}{cv2\PYGZus{}imshow}\PYG{p}{(}\PYG{n}{imagem}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{imagem}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{img2} \PYG{o}{=} \PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{expand\PYGZus{}dims}\PYG{p}{(}\PYG{n}{imagem}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{img2}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{imagem}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{colorbar}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{grid}\PYG{p}{(}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{predictions\PYGZus{}array} \PYG{o}{=} \PYG{n}{probability\PYGZus{}model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img2}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{predictions\PYGZus{}array}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{predicted\PYGZus{}label} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{predictions\PYGZus{}array}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{predicted\PYGZus{}label}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plot\PYGZus{}value\PYGZus{}array}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{predictions\PYGZus{}array}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xticks}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{l+m+mi}{7}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{l+m+mi}{9}\PYG{p}{]}\PYG{p}{,} \PYG{n}{rotation}\PYG{o}{=}\PYG{l+m+mi}{45}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}The labels are wrong}
\end{sphinxVerbatim}

Il est important de parler des impacts positif et négatif  de l’intelligence artificielle dans le but de répondre à la thèse en répondant à  une des  sous\sphinxhyphen{}questions  de notre thèse: Est\sphinxhyphen{}ce que l’intelligence artificielle peut constituer un bénéfice pour l’être humain?

Pour commencer, l’intégration de l’intelligence artificielle à notre vie de tous les jours ainsi que dans plusieurs tâches amènerait plusieurs bénéfices importants.

Qui dit programme, dit un taux d’erreur qui diminue. En effet, l’erreur humaine est une partie flagrante de plusieurs métiers. C’est tout à fait normal qu’un être humain fasse des erreurs de temps en temps d’où vient la phrase : « L’erreur est humaine», mais réduire ce nombre d’erreurs au minimum est primordial pour certaines tâches. L’utilisation d’une intelligence artificielle bien programmée permet de réduire le taux d’erreurs tout en augmentant la précision du résultat. Cela est possible, car un programme peut parcourir une large base de données et appliquer des algorithmes en peu de temps, tandis que l’être humain prendrait des mois et des mois pour faire cela. Un exemple moderne, serait l’utilisation de l’intelligence artificielle dans les prévisions météo. En effet, ceux\sphinxhyphen{}ci deviennent de plus en plus précis avec l’implémentation de l’intelligence artificielle ainsi que l’amélioration des algorithmes.

Un autre aspect intéressant de l’intelligence artificielle, c’est qu’elle peut remplacer l’être humain dans des tâches dangereuses qui pourrait risquer la vie de des individus, mais qui est sans risques pour l’intelligence artificielle. Un exemple serait le robot Curiosity, qui lancé en novembre 2011 pour atteindre la planète Mars, se trouve toujours sur cette planète en date du 19 novembre 2020 dans des conditions impossible pour qu’un être humain y soit resté aussi longtemps. Le robot a pour but d’examiner la biologie, la géologie  et la radiation de Mars, dans le but de préparer une exploration humaine dans le futur.

Les conditions de travail font qu’un être humain travaille environ 40 heures par semaine en incluant les pauses. Si ce travail était automatisé et remplacé par une intelligence artificielle, celui\sphinxhyphen{}ci n’a pas besoin de pause et peut travailler 24 heures sur 24, 7 jours sur 7. De plus, un être humain devient de moins en moins efficace vers la fin de la journée ou vers la fin de la semaine à cause de la fatigue ou bien de l’ennui. Un intelligence artificielle sera sûrement plus efficace que l’être humain et elle sera aussi consistante dans sa rapidité d’exécution.Cette ennuie vient souvent des travaux répétitifs. Ces tâches banales peuvent souvent être automatisées en remplaçant l’être humain par un intelligence artificielle. Donnant plus de temps à l’être humain pour ce concentrer sur des tâches plus exigeantes et passionnantes pour celui\sphinxhyphen{}ci.

Quand on parle de rapidité, l’être humain est très lent comparé à l’intelligence artificielle. En effet, l’utilisation de l’intelligence artificielle pour la prise de décision permet de prendre ceux\sphinxhyphen{}ci extrêmement rapidement avec une précision qui dépend de la qualité de leurs bases de données. En effet, une base de données fiable et bien construite permet à l’intelligence artificielle de prendre des bonnes décisions rapidement. Un être humain, de l’autre côté, doit analyser une plus petite base de données qui est dans sa mémoire en prenant plus de temps. Un des exemples serait l’utilisation de l’intelligence artificielle dans les jeux d’échecs. L’intelligence artificielle à accès à des milliers et des milliers de parties dans sa base de données. Alors lorsque son adversaire humain joue le coup  Nc3 (Cavalier sur la case C3), l’ordinateur analyse toutes les parties où ce coup c’est fait et en ressort le meilleur coup pour contrer celui\sphinxhyphen{}ci, et ce, en moins d’une seconde. De plus, la prise de décision de l’intelligence artificielle ne va pas seulement s’arrêter au jeu d’échec. Nous voyons déjà l’industrie médical, ce faire aider dans la prise de décision par l’intelligence artificielle en plus de des nouveaux programmes qui se font développés en ce moment. En effet, ceux\sphinxhyphen{}ci ont pour but d’aider les professionnels de la santé dans des diagnostics, surveillances de patients, et plusieurs autres. Google sont en train de travailler sur leur projet: Google Health, en étudiant sur l’utilisation de l’intelligence artificielle dans le but d’assister au diagnostic de cancer

Certes, ces merveilleux bénéfices ne viennent pas sans coût. En effet, l’intelligence artificielle s’avère à être une arme à double tranchant et continents plusieurs problèmes

Un de ces  problèmes majeurs est le biais de l’intelligence artificielle intégré dans l’algorithme de manière involontaire ou intentionnelle par la façon dont celui\sphinxhyphen{}ci est entraîné ou programmé. Un exemple flagrant serait le programme Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) qui à signaler à tort des personnes ayant la peau foncée presque deux fois plus que des personnes ayant la peau blanche(45\% à 24\%) devant la cour juridique aux États\sphinxhyphen{}Unis. Un intelligence artificielle programmé par Microsoft Corporation dans le but d’interagir avec les internautes, s’est fait enlever rapidement après un entraînement avec l’interaction d’internautes raciste. Cela a mené le robot à dire des phrases vulgaires et inappropriées telles que : “@brightonus33 Hitler was right I hate the jews” et plusieurs autres avant que celui\sphinxhyphen{}ci voit la fin de ses jours 16 heures après son arrivée sur Twitter.

Comme mentionné plus haut, l’intelligence artificielle à apporter et va apporter plusieurs nouveaux emplois spécialisés dans l’intelligence artificielle, mais plusieurs autres emplois vont voir leur fin arriver à grand pas avec la montée de l’intelligence artificielle. Cela c’est déjà fait avec la révolution industrielle, qui avec l’arrivée de la machine à vapeur, un énorme taux de chômage à surgit. L’intelligence artificielle devrait, tout comme la machine à vapeur, augmenter le besoin de certains emplois et créer des emplois qui requièrent un plus haut degré en éducation tout en éradiquant des emplois auxquels aucune caractéristique uniquement humaine est requise.

Aussi, avec la montée de l’intelligence artificielle ainsi que l’omniprésence de la technologie qui à créer une multitude d’interconnection entre tous les pays, chaque pays va définir des lois et des règlements sur l’intelligence artificielle. Dans un monde idéal, tous les humains s’entendent sur les mêmes lois et règlements pour éviter des conflits avec d’autres pays face à des décisions par rapport à l’intelligence artificielle d’un pays. Malheureusement, comme l’Histoire nous l’a si bien démontré, essayer d’établir des règles communes s’avère difficile, et de les faire respecter, encore plus. Des différence ce font déjà voir entre les puissances du mondes face à l’intelligence artificielle avec l’Union Européenne qui sont déjà entrains de pousser des mesures stricte pour le développement et l’utilisation de l’intelligence artificielle avec le ‘White Paper on Artificial Intelligence \textendash{} A European Approach to Excellence and Trust’ ,publié en 2020, contrairement aux États \sphinxhyphen{} Unis et la Chine qui permettent à leur compagnie d’utiliser l’intelligence artificielle plus librement.

L’intelligence artificielle va augmenter l’efficacité et la rapidité de plusieurs programmes. Cela ne néglige pas les programmes de piratages informatiques, qui eux aussi vont voir une amélioration drastique avec l’implémentation de l’intelligence artificielle. Cela va donc augmenter aussi la rapidité et l’efficacité des piratages informatiques menant sûrement à une augmentation de ceux\sphinxhyphen{}ci ce qui causera plusieurs problèmes majeurs, jusqu’à temps qu’une solution soit trouvée.

L’utilisation de l’intelligence artificielle dans des buts de tuer des individus est un grave danger. Comme mentionné dans le rapport, l’entraînement de l’intelligence se fait à partir d’une grande base de données fiable. Dans un contexte d’une guerre contre le terrorisme, avoir une base de données sur les terroristres s’avère très difficile et peu fiable, car la plus part d’entre eux s’habille comme des civiles. De plus, cette technologie, une fois tombée dans les mains des terroristes, pourrait semer terreur au sein d’un pays comme le démontre très bien la vidéo Slaughterbots (https://www.youtube.com/watch?v=HipTO\_7mUOw\&ab\_channel=FutureofLifeInstitute) qui promouvoit l’interdiction de l’usage robot tueur.

Comme mentionné dans ce rapport, l’utilisation de plusieurs tests peuvent permettre de découvrir si un robot à de l’intelligence artificielle semblable ou supérieure à celle d’un humain. Le test de Turing, nommé après Alan Turing, proposait que si un ordinateur était capable de se dissimuler parmi un autre être humain lors d’une période de question plus 50\% du temps, celui\sphinxhyphen{}ci est considéré comme s’il avait de l’intelligence artificielle. Avec, l’avancement en intelligence artificielle, il s’avère de plus en plus difficile de différencier un être humain d’un robot. En effet, C’est en 2014, que le programme Eugene Goostman fut le premier à passer le test de Turing, et cela va en augmentant. D’autre exemple de l’utilité du test de Turing, serait sa version à l’envers. Donc un humain qui tente de prouver à un ordinateur qu’il est réellement humain. Cela se voit quasiment tous les jours avec les tests Captcha.

https://www.theguardian.com/inequality/2017/aug/08/rise\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}racist\sphinxhyphen{}robots\sphinxhyphen{}how\sphinxhyphen{}ai\sphinxhyphen{}is\sphinxhyphen{}learning\sphinxhyphen{}all\sphinxhyphen{}our\sphinxhyphen{}worst\sphinxhyphen{}impulses
https://bernardmarr.com/default.asp?contentID=1827
https://www.forbes.com/sites/bernardmarr/2020/03/02/is\sphinxhyphen{}artificial\sphinxhyphen{}intelligence\sphinxhyphen{}ai\sphinxhyphen{}a\sphinxhyphen{}threat\sphinxhyphen{}to\sphinxhyphen{}humans/?sh=2aa4186f205d
https://blog.oup.com/2018/01/alan\sphinxhyphen{}turing\sphinxhyphen{}evil\sphinxhyphen{}artificial\sphinxhyphen{}intelligence/
https://en.wikipedia.org/wiki/Tay\_(bot)
https://ec.europa.eu/info/sites/info/files/commission\sphinxhyphen{}white\sphinxhyphen{}paper\sphinxhyphen{}artificial\sphinxhyphen{}intelligence\sphinxhyphen{}feb2020\_en.pdf
https://www.theguardian.com/news/2020/oct/15/dangerous\sphinxhyphen{}rise\sphinxhyphen{}of\sphinxhyphen{}military\sphinxhyphen{}ai\sphinxhyphen{}drone\sphinxhyphen{}swarm\sphinxhyphen{}autonomous\sphinxhyphen{}weapons

https://www.newyorker.com/tech/annals\sphinxhyphen{}of\sphinxhyphen{}technology/what\sphinxhyphen{}comes\sphinxhyphen{}after\sphinxhyphen{}the\sphinxhyphen{}turing\sphinxhyphen{}test
https://www.brookings.edu/research/malevolent\sphinxhyphen{}soft\sphinxhyphen{}power\sphinxhyphen{}ai\sphinxhyphen{}and\sphinxhyphen{}the\sphinxhyphen{}threat\sphinxhyphen{}to\sphinxhyphen{}democracy/
https://www.forbes.com/sites/bernardmarr/2020/02/10/8\sphinxhyphen{}powerful\sphinxhyphen{}examples\sphinxhyphen{}of\sphinxhyphen{}ai\sphinxhyphen{}for\sphinxhyphen{}good/?sh=7cccfe02d18a
https://towardsdatascience.com/advantages\sphinxhyphen{}and\sphinxhyphen{}disadvantages\sphinxhyphen{}of\sphinxhyphen{}artificial\sphinxhyphen{}intelligence\sphinxhyphen{}182a5ef6588c
https://en.wikipedia.org/wiki/Curiosity\_(rover)\#Goals\_and\_objectives
https://link.springer.com/article/10.1007/s41649\sphinxhyphen{}019\sphinxhyphen{}00096\sphinxhyphen{}0

Il est important de parler des impacts positifs et négatifs de l’intelligence
artificielle dans le but de bien comprendre ce que cette technologie peut apporter
à l’évolution de la société. C’est pour cela que cette section va répondre à la
sous\sphinxhyphen{}question de la thèse: Est\sphinxhyphen{} ce que l’intelligence artificielle peut constituer
un bénéfice pour l’être humain.

Pour commencer, l’intégration de l’intelligence artificielle à notre vie de tous
les jours ainsi que dans plusieurs tâches pourrait amener plusieurs bénéfices
importants.

Qui dit programme, dit souvent un taux d’erreur qui diminue. En effet, l’erreur
humaine est présente et joue un gros rôle dans plusieurs métiers. L’erreur est humaine
, mais minimiser l’effort tout en maximisant la précision est primordial pour
certaines tâches. L’utilisation d’une intelligence artificielle bien entraînée
permet de réduire le taux d’erreurs et le temps requis à l’exécution d’une tâche.
Cela est possible, car un programme assisté par l’intelligence artificielle peut
parcourir un large jeu de données et appliquer des algorithmes en peu de temps,
tandis que l’être humain prendrait des mois et des mois pour faire cela. Un exemple
moderne serait l’utilisation de l’intelligence artificielle dans les prévisions météo.
Ceux\sphinxhyphen{}ci deviennent donc de plus en plus précis avec l’aide de l’apprentissage
machine ainsi que l’amélioration des algorithmes.

L’IA peut assister l’être humain dans des tâches dangereuses qui pourraient risquer
la vie d’individus, mais qui est sans risques pour l’intelligence artificielle.
Un exemple serait le robot \sphinxhref{https://mars.nasa.gov/msl/home/}{Curiosity} lancé en novembre 2011 dans le but d’atteindre
la planète Mars. Il se trouve toujours sur cette planète en date du 19 novembre
2020 dans des conditions impossibles pour qu’un être humain y soit resté aussi
longtemps. Celui\sphinxhyphen{}ci est contrôlé par l’intelligence artificielle dans le but
d’accomplir plusieurs tâches. Ses tâches consistent à examiner la biologie, la
géologie  et la radiation de Mars, afin de préparer une exploration humaine dans le futur.

Les conditions de travail standard dictent qu’un être humain travaille environ
40 heures par semaine en incluant les pauses. De plus, ce ne sont pas toujours
40 heures productives. Les fins de journées et les fins de semaine sont souvent
peu productives. En comparaison, un ordinateur n’a pas besoin de pause et peut
travailler 24 heures sur 24, 7 jours sur 7. L’intelligence artificielle sera
sûrement plus efficace qu’une majorité des travailleurs  et  aussi plus constante
dans sa vitesse d’exécution. Cet ennui est souvent causé souvent par des travaux
répétitifs. Ces tâches banales peuvent être automatisées par l’IA. Donnant plus de
temps aux travailleurs pour se concentrer sur des tâches plus exigeantes et passionnantes.
Comme les ordinateurs le font déjà dans plusieurs domaines, tel celui de la finance
où un apprentissage machine s’occupe de détecter des fraudes potentielles dans
les transactions des clients.

Quand on parle de rapidité, l’être humain est très lent comparé à l’intelligence
artificielle. En effet, l’utilisation de l’intelligence artificielle pour la prise
de décision permet de prendre ceux\sphinxhyphen{}ci extrêmement rapidement avec une précision qui
dépend de la qualité de leurs bases de données. Effectivement, un jeu de données fiable
et bien construit permet à l’intelligence artificielle de prendre des bonnes décisions
rapidement. Un être humain, de l’autre côté, doit analyser une plus petite quantité de
données directement sous son nez en prenant plus de temps. Un des exemples serait
l’utilisation de l’intelligence artificielle dans les jeux d’échecs. L’intelligence
artificielle à accès à des milliers et des milliers de parties dans son jeu de
données. Alors, lorsque son adversaire humain joue le coup  Nc3 (Cavalier sur la case C3),
l’ordinateur analyse toutes les parties où ce coup c’est fait et en ressort le meilleur
coup pour contrer celui\sphinxhyphen{}ci, et ce, en un temps record. De plus, la prise de décision de
l’intelligence artificielle ne va pas seulement s’arrêter au jeu d’échec. Nous voyons
déjà l’industrie médicale se faire aider dans la prise de décision par l’intelligence
artificielle en plus des nouveaux programmes qui se font développer en ce moment. Ceux\sphinxhyphen{}ci
ont pour but d’aider les professionnels de la santé dans des diagnostics, surveillances
de patients, et plusieurs autres. La compagnie Google est en train de développer  leur
projet \sphinxhref{https://health.google/}{Google Health} Pour se faire, ils étudient l’utilisation de l’intelligence artificielle
dans le but d’assister au diagnostic de cancer, prévenir l’aveuglement et plusieurs autres.

La croissance exponentielle de l’intelligence artificielle dans le monde a affecté
de manière abrupte le nombre de travail qui requiert des capacités en intelligence
artificielle, et donc, a créé plusieurs nouveaux emplois dans ce domaine.Grâce à cela,
la part des emplois qui requièrent des capacités en intelligence artificielle a augmenté
de 4,5 fois depuis 2013 aux États\sphinxhyphen{}Unis sur le site web \sphinxhref{https://ca.indeed.com/?r=us}{indeed.com}.

Certes, ces merveilleux bénéfices ne viennent pas sans coût.Or, l’intelligence artificielle
s’avère à être une arme à double tranchant et continents plusieurs problèmes

Un de ces  problèmes majeurs est le biais de l’intelligence artificielle intégrée dans
le modèle de manière involontaire ou intentionnelle par la façon dont celui\sphinxhyphen{}ci est entraîné
ou programmé. Un exemple flagrant serait le programme Correctional Offender Management
Profiling for Alternative Sanctions (\sphinxhref{https://en.wikipedia.org/wiki/COMPAS\_(software)}{COMPAS}) qui a signalé à tort des personnes ayant la
peau foncée presque deux fois plus que des personnes ayant la peau blanche(45 \% à 24 \%)
devant la cour juridique aux États\sphinxhyphen{}Unis. Un autre exemple serait l’intelligence artificielle
programmée par Microsoft Corporation dans le but d’interagir avec les internautes.
Prénommé «\sphinxhref{https://twitter.com/tayandyou?lang=en}{Tay}», le bot s’est rapidement fait retirer après un entraînement avec l’interaction
d’internautes racistes. Cela a mené le robot à dire des phrases vulgaires et inappropriées
avant que celui\sphinxhyphen{}ci voit la fin de ses jours 16 heures après son arrivée sur Twitter.
Le problème provient donc d’un jeu de données non fiable où mal construit qui induit
l’apprentissage machine en erreur.

Tel que mentionné plus haut, l’intelligence artificielle a apporté et va apporter plusieurs
nouveaux emplois spécialisés dans l’intelligence artificielle, mais plusieurs autres emplois
vont voir leur fin arriver à grands pas avec la montée de l’intelligence artificielle. Cela
c’est déjà fait avec la révolution industrielle, qui, avec l’arrivée de la machine à vapeur,
avait fait grimper le taux de chômage à une vitesse fulgurante. L’intelligence artificielle
devrait, tout comme la machine à vapeur, augmenter le besoin de certains emplois et créer des
emplois qui requièrent un plus haut niveau d’étude en éducation tout en éradiquant des emplois
auxquels aucune caractéristique uniquement humaine est requise. Il reste à noter que l’être
humain s’en est quand même bien sortie de la révolution industrielle, contrairement aux idées
pessimistes quant au futur proliférées à l’époque.

Par ailleurs, l’omniprésence de la technologie a créé une multitude d’interconnexions entre
tous les pays. En plus, avec l’implémentation de l’intelligence artificielle, chaque pays va
définir des lois et des règlements sur l’intelligence artificielle.
Dans un monde idéal, tous les êtres humains s’entendent sur les mêmes lois et règlements pour
éviter des conflits avec d’autres pays. Ces conflits seraient à cause de décisions par rapport
à l’intelligence artificielle qu’un pays a choisi et qui mène à une contradiction avec un ou
plusieurs autres pays. Malheureusement, comme l’Histoire nous l’a si bien démontré, essayer
d’établir des règles communes s’avère difficile, et de les faire respecter, encore plus. Des différences
se font déjà voir entre les puissances du monde face à l’intelligence artificielle avec l’Union
Européenne qui est déjà entrain de pousser pour des mesures plus strictes pour le développement et
l’utilisation de l’intelligence artificielle avec le ‘White Paper on Artificial Intelligence \textendash{}
A European Approach to Excellence and Trust’ ,publié en 2020. Au contraire, les États \sphinxhyphen{} Unis
et la Chine permettent à leur compagnie d’utiliser l’intelligence artificielle plus librement.

L’intelligence artificielle va augmenter l’efficacité et la rapidité de plusieurs programmes.
Cela n’exclut pas les programmes de piratages informatiques, qui eux aussi vont voir une
amélioration drastique avec l’implémentation de l’intelligence artificielle. Cela va donc
augmenter aussi la rapidité et l’efficacité des piratages informatiques menant sûrement à
une augmentation de ceux\sphinxhyphen{}ci ce qui causera plusieurs problèmes majeurs, jusqu’à temps
qu’une solution soit trouvée.

L’utilisation de l’intelligence artificielle dans des buts de tuer des individus est un grave
danger. Tel que mentionné dans le rapport, l’entraînement de l’intelligence se fait à partir
d’un grand jeu de données fiables. Dans un contexte d’une guerre contre le terrorisme, avoir
un jeu de données sur les terroristres s’avère très difficile et peu fiable, car la plupart
d’entre eux s’habille comme des civiles. De plus, cette technologie, une fois tombée dans les mains
des terroristes, pourrait semer terreur au sein d’un pays comme le démontre très bien la vidéo
\sphinxhref{https://www.youtube.com/watch?v=HipTO\_7mUOw\&ab\_channel=FutureofLifeInstitute}{Slaughterbots}
qui promeut l’interdiction de l’usage robot tueur.

En conclusion, l’implémentation de l’intelligence artificielle ainsi que la croissance
exponentielle de celle\sphinxhyphen{}ci va rapporter une tonne de bénéfices tel l’élimination de l’erreur humaine,
l’utilisation de celle\sphinxhyphen{}ci dans des tâches dangereuses, la disponibilité 24/7 de celle\sphinxhyphen{}ci,
la rapidité de prise de décision et les emplois dans ce domaine. De l’autre côté, si l’on veut
que ces bénéfices portent fruit, il faut limiter ou éliminer les impacts négatifs de l’intelligence
artificielle. Cela va se faire graduellement par l’implémentation de règles mondiales sur les jeux
de données utilisés dans l’intelligence machine, l’intelligence machine en temps que tel, l’utilisation
de l’intelligence artificielle dans un environnement de guerre, et ce, dans l’accord de la majorité
des pays en plus de développer et améliorer la cybersécurité. Une idée intéressante pour régler le
problème des jeux de données pourrait être de standardiser les jeux de données qui ne sont pas biaisés
dans le but d’éviter les problèmes. C’est déjà ce que le NIST fait en fournissant des jeux de données
fiables gratuitement.

Finalement, quel est le fonctionnement de l’intelligence artificielle et comment devrait\sphinxhyphen{}elle être utilisée
afin de bénéficier l’être humain? L’hypothèse émise était que si son développement se fait de manière
éthique et s’il est bien encadré, nous pourrions en retirer plus d’avantages que d’inconvénients. Il
était donc important de comprendre le fonctionnement de cette technologie pour pouvoir expliquer et
rationaliser l’utilisation bénéfique de l’intelligence artificielle et d’ainsi le documenter.

Finalement, quel est le fonctionnement de l’intelligence artificielle et
comment devrait\sphinxhyphen{}elle être utilisée afin de bénéficier l’être humain?
L’hypothèse émise était que si son développement se fait de manière éthique
et s’il est bien encadré, nous pourrions en retirer plus d’avantages que
d’inconvénients. Il était donc important de comprendre le fonctionnement
de cette technologie pour pouvoir expliquer et rationaliser l’utilisation
bénéfique de l’intelligence artificielle et d’ainsi le documenter.

Pour ce faire, il a fallu procéder à l’écriture d’un programme d’OCR, une
forme simple d’intelligence artificielle qui a pour but de reconnaître des
caractères écrits à la main. Grâce à l’information acquise lors de l’écriture
de celui\sphinxhyphen{}ci ainsi que toute la documentation lue pour la préparation du
programme, il a été plus facile de comprendre les aspects d’un réseau neuronal
dans le but de documenter chaque composante du réseau neuronal.

Ce que nous pouvons conclure d’un réseau neuronal après notre documentation,
c’est que cette “intelligence” artificielle, n’est rien d’autre qu’un paquet
de fonctions avec des paramètres qui ont été ajustés par une méthode d’optimisation
dénommée “Back propagation”. Cette méthode est composée de fonctions qui
utilisent des notions de mathématiques telles que les dérivées. Cet algorithme
a lieu lors de chaque “epoch%
\begin{footnote}[2]\sphinxAtStartFootnote
Une “epoch” étant un cycle complet où l’algorithme a traité
le jeu de données qui lui a été fournie une seule fois.
%
\end{footnote}” dans le but d’ajuster l’algorithme d’OCR
graduellement.

Donc, cet algorithme « intelligent ” n’est pas capable de prendre des
décisions elle\sphinxhyphen{}même et doit être surveillé et entraîné par un être humain
à l’aide d’un jeu de données.Cela dans le but de pouvoir répondre à la tâche
précise à la\sphinxhyphen{}quel l’algorithme s’est fait assigner, qui est dans notre
cas la reconnaissance optique des chiffres de 0 à 9. Alors, un algorithme
qui est bon ou mauvais dans sa tâche et donc qui a une bonne ou mauvaise
précision est principalement déterminé par la façon dont l’algorithme a
été entraîné et si le jeu de données utilisé pour l’entraîner est fiable
et diversifié. Dans notre cas, la précision est calculée par le nombre de
prédiction réussite sur le nombre total de prédiction.C’est donc l’entraînement
que provient une partie des biais de l’intelligence artificielle, et donc
un des inconvénients qu’on avait cité dans notre hypothèse.

L’autre inconvénient qui a été mentionné lors de l’hypothèse est l’importante
quantité d’emploi qui risque de disparaître. Or, tel que mentionné dans la
section sur les impacts de l’intelligence artificielle, il n’y a pas seulement
cet inconvénient, et ces autres inconvénients sont accompagnés de plusieurs
avantages intéressants.

Comme il est décrit dans la section des bienfaits et inconvénients, l’usage
de l’apprentissage machine peut amener beaucoup d’avantages ainsi que des
inconvénients. Ces principaux avantages se résument à,
l’élimination de l’erreur humaine, l’utilisation de l’IA dans des tâches
dangereuses, la disponibilité 24/7 de celle\sphinxhyphen{}ci, la rapidité de prise de
décision et les emplois dans ce domaine. Tandis que les inconvénient se
résument au biais de l’IA, diminution de certains types d’emploi, les conflits
mondiaux lié à celle\sphinxhyphen{}ci, l’amélioration des “hacks” et l’utilisation de
celle\sphinxhyphen{}ci dans le but de tuer. Si l’on veut avoir les bénéfices de l’intelligence
artificielle, il faut d’abord s’occuper de diminuer l’impact des inconvénients.
La bonne nouvelle étant que ces inconvénients peuvent être quasi inexistants
si l’IA est implémentée en suivant dans un bon cadre strict ainsi que des
mesures de sécurité. Par exemple, des règles sur l’utilisation des bases
de données et des réglementations sur celles\sphinxhyphen{}ci pourraient diminuer les
biais dans les programmes d’apprentissage machine. Si ces conditions sont
respectées, il est préférable de penser que l’usage de l’intelligence
artificielle pourrait faire évoluer la société.

Pour répondre à la thèse, l’intelligence artificielle fonctionne par l’étude
de grosses bases de données par un programme. Celui\sphinxhyphen{}ci va ensuite faire
varier ses paramètres clés dans le but d’ajuster certaines fonctions. Ces
fonctions permettent de trouver des tendances dans le jeu de données et de
les utiliser dans le but de répondre à la tâche attribuée. De plus,
l’intelligence artificielle peut constituer un bénéfice pour l’être humain
à condition que celle\sphinxhyphen{}ci soit bien encadrée.

Il ne faut toutefois pas écarter le fait que le futur n’est jamais certain,
et qu’on ne peut prédire à 100\% ce que l’intelligence artificielle va
ressembler dans 50 ans. Mais, avec les avancées technologiques des dernières
années qui ne semblent pas s’arrêter, il serait juste de croire que l’IA
à un futur prometteur. Avec ces avancés prometteuses, ce pourrait\sphinxhyphen{}il qu’il
y aurait une sorte d’intelligence au\sphinxhyphen{}delà de celle humaine et artificielle ?


\bigskip\hrule\bigskip




\begin{sphinxthebibliography}{Les cont}
\bibitem[InnovationQuebec, 2018]{zbib:gouvqc}
et Innovation Québec, É. (2018). \sphinxstyleemphasis{Les avantages et inconvénients de l’intelligence artificielle}.
\bibitem[Goodfellow et al., 2016]{zbib:goodfellow-et-al-2016}
Goodfellow, I., Bengio, Y., \& Courville, A. (2016). \sphinxstyleemphasis{Deep Learning}. MIT Press. http://www.deeplearningbook.org.
\bibitem[Google, n.d.]{zbib:trendsai}
Google (n.d.). \sphinxstyleemphasis{Compare}.
\bibitem[Grother et al., 2019]{zbib:nistbias}
Grother, P., Ngan, M., \& Hanaoka, K. (2019). \sphinxstyleemphasis{Face Recognition Vendor Test (FRVT) Part 3: Demographic Effects}. NIST.
\bibitem[Ireland, 2012]{zbib:harvardeliza}
Ireland, C. (2012). \sphinxstyleemphasis{Alan Turing at 100}.
\bibitem[LAURO, n.d.]{zbib:ubiquity}
LAURO, D. M. (n.d.). \sphinxstyleemphasis{HUMAN BRAIN AND NEURAL NETWORK BEHAVIOR A COMPARISON}.
\bibitem[Metz, 2020]{zbib:cnnportland}
Metz, R. (2020). \sphinxstyleemphasis{Portland passes broadest facial recognition ban in the US}.
\bibitem[Nielsen, 2019]{zbib:michael}
Nielsen, M. A. (2019). \sphinxstyleemphasis{Neural Networl and Deep Learning}.
\bibitem[Popper, 2016]{zbib:nytimes}
Popper, N. (2016). \sphinxstyleemphasis{The Robots Are Coming for Wall Street}.
\bibitem[RFisher \& Wolfart, 2003]{zbib:hipr2}
R. Fisher, S. Perkins, A. W., \& Wolfart, E. (2003). \sphinxstyleemphasis{Pixel Values}.
\bibitem[Reddy, 2019]{zbib:preprocessing}
Reddy, S. (2019). \sphinxstyleemphasis{Pre\sphinxhyphen{}Processing in OCR}.
\bibitem[Simonite, 2018]{zbib:wiredai}
Simonite, T. (2018). \sphinxstyleemphasis{The WIRED Guide to Artificial Intelligence}.
\bibitem[IBM Cloud Education, 2020]{zbib:ibmai}
IBM Cloud Education (2020). \sphinxstyleemphasis{Artificial Intelligence (AI)}.
\bibitem[Les contributeurs de Wikipedia, 2020]{zbib:wikitf}
Les contributeurs de Wikipedia (2020). \sphinxstyleemphasis{TensorFlow}.
\bibitem[The Numpy documentation team, 2020]{zbib:numpy}
The Numpy documentation team (2020). \sphinxstyleemphasis{About us}.
\bibitem[The TensorFlow developper team, 2015]{zbib:tfpaper}
The TensorFlow developper team (2015). \sphinxstyleemphasis{TensorFlow: Large\sphinxhyphen{}Scale Machine Learning on Heterogeneous Distributed Systems}.
\bibitem[The TensorFlow developper team, 2020]{zbib:tfmain}
The TensorFlow developper team (2020). \sphinxstyleemphasis{TensorFlow}.
\end{sphinxthebibliography}







\renewcommand{\indexname}{Index}
\printindex
\end{document}